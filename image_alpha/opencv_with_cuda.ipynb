{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### VALUES\n",
    "NUM_REPEAT = 10000\n",
    "\n",
    "### Read source image\n",
    "img_src = cv2.imread(\"data/Rist.png\")\n",
    "plt.imshow(img_src)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU = 0.506326961517334[msec]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = 0.4563901901245117[msec]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Run with CPU\n",
    "time_start = time.time()\n",
    "for i in range (NUM_REPEAT):\n",
    "    img_dst = cv2.resize(img_src, (300, 300))\n",
    "time_end = time.time()\n",
    "print (\"CPU = {0}\".format((time_end - time_start) * 1000 / NUM_REPEAT) + \"[msec]\")\n",
    "plt.imshow(img_dst)\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "\n",
    "### Run with GPU\n",
    "img_gpu_src = cv2.cuda_GpuMat() # Allocate device memory only once, as memory allocation seems to take time...\n",
    "img_gpu_dst = cv2.cuda_GpuMat()\n",
    "time_start = time.time()\n",
    "for i in range (NUM_REPEAT):\n",
    "    img_gpu_src.upload(img_src)\n",
    "    img_gpu_dst = cv2.cuda.resize(img_gpu_src, (300, 300))\n",
    "    img_dst = img_gpu_dst.download()\n",
    "time_end = time.time()\n",
    "print (\"GPU = {0}\".format((time_end - time_start) * 1000 / NUM_REPEAT) + \"[msec]\")\n",
    "plt.imshow(img_dst)\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "print(cv2.cuda.getCudaEnabledDeviceCount())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module cv2.cuda in cv2:\n",
      "\n",
      "NAME\n",
      "    cv2.cuda\n",
      "\n",
      "FUNCTIONS\n",
      "    BroxOpticalFlow_create(...)\n",
      "        BroxOpticalFlow_create([, alpha[, gamma[, scale_factor[, inner_iterations[, outer_iterations[, solver_iterations]]]]]]) -> retval\n",
      "        .\n",
      "    \n",
      "    CascadeClassifier_create(...)\n",
      "        CascadeClassifier_create(filename) -> retval\n",
      "        .   @brief Loads the classifier from a file. Cascade type is detected automatically by constructor parameter.\n",
      "        .   \n",
      "        .       @param filename Name of the file from which the classifier is loaded. Only the old haar classifier\n",
      "        .       (trained by the haar training application) and NVIDIA's nvbin are supported for HAAR and only new\n",
      "        .       type of OpenCV XML cascade supported for LBP. The working haar models can be found at opencv_folder/data/haarcascades_cuda/\n",
      "    \n",
      "    DensePyrLKOpticalFlow_create(...)\n",
      "        DensePyrLKOpticalFlow_create([, winSize[, maxLevel[, iters[, useInitialFlow]]]]) -> retval\n",
      "        .\n",
      "    \n",
      "    DescriptorMatcher_createBFMatcher(...)\n",
      "        DescriptorMatcher_createBFMatcher([, normType]) -> retval\n",
      "        .   @brief Brute-force descriptor matcher.\n",
      "        .   \n",
      "        .       For each descriptor in the first set, this matcher finds the closest descriptor in the second set\n",
      "        .       by trying each one. This descriptor matcher supports masking permissible matches of descriptor\n",
      "        .       sets.\n",
      "        .   \n",
      "        .       @param normType One of NORM_L1, NORM_L2, NORM_HAMMING. L1 and L2 norms are\n",
      "        .       preferable choices for SIFT and SURF descriptors, NORM_HAMMING should be used with ORB, BRISK and\n",
      "        .       BRIEF).\n",
      "    \n",
      "    Event_elapsedTime(...)\n",
      "        Event_elapsedTime(start, end) -> retval\n",
      "        .\n",
      "    \n",
      "    FarnebackOpticalFlow_create(...)\n",
      "        FarnebackOpticalFlow_create([, numLevels[, pyrScale[, fastPyramids[, winSize[, numIters[, polyN[, polySigma[, flags]]]]]]]]) -> retval\n",
      "        .\n",
      "    \n",
      "    FastFeatureDetector_create(...)\n",
      "        FastFeatureDetector_create([, threshold[, nonmaxSuppression[, type[, max_npoints]]]]) -> retval\n",
      "        .\n",
      "    \n",
      "    GpuMat_defaultAllocator(...)\n",
      "        GpuMat_defaultAllocator() -> retval\n",
      "        .\n",
      "    \n",
      "    GpuMat_setDefaultAllocator(...)\n",
      "        GpuMat_setDefaultAllocator(allocator) -> None\n",
      "        .\n",
      "    \n",
      "    HOG_create(...)\n",
      "        HOG_create([, win_size[, block_size[, block_stride[, cell_size[, nbins]]]]]) -> retval\n",
      "        .   @brief Creates the HOG descriptor and detector.\n",
      "        .   \n",
      "        .       @param win_size Detection window size. Align to block size and block stride.\n",
      "        .       @param block_size Block size in pixels. Align to cell size. Only (16,16) is supported for now.\n",
      "        .       @param block_stride Block stride. It must be a multiple of cell size.\n",
      "        .       @param cell_size Cell size. Only (8, 8) is supported for now.\n",
      "        .       @param nbins Number of bins. Only 9 bins per cell are supported for now.\n",
      "    \n",
      "    NvidiaOpticalFlow_1_0_create(...)\n",
      "        NvidiaOpticalFlow_1_0_create(width, height[, perfPreset[, enableTemporalHints[, enableExternalHints[, enableCostBuffer[, gpuId]]]]]) -> retval\n",
      "        .   @brief Instantiate NVIDIA Optical Flow\n",
      "        .   \n",
      "        .       @param width Width of input image in pixels.\n",
      "        .       @param height Height of input image in pixels.\n",
      "        .       @param perfPreset Optional parameter. Refer [NV OF SDK documentation](https://developer.nvidia.com/opticalflow-sdk) for details about presets.\n",
      "        .                         Defaults to NV_OF_PERF_LEVEL_SLOW.\n",
      "        .       @param enableTemporalHints Optional parameter. Flag to enable temporal hints. When set to true, the hardware uses the flow vectors\n",
      "        .                                  generated in previous call to calc() as internal hints for the current call to calc().\n",
      "        .                                  Useful when computing flow vectors between successive video frames. Defaults to false.\n",
      "        .       @param enableExternalHints Optional Parameter. Flag to enable passing external hints buffer to calc(). Defaults to false.\n",
      "        .       @param enableCostBuffer Optional Parameter. Flag to enable cost buffer output from calc(). Defaults to false.\n",
      "        .       @param gpuId Optional parameter to select the GPU ID on which the optical flow should be computed. Useful in multi-GPU systems. Defaults to 0.\n",
      "    \n",
      "    ORB_create(...)\n",
      "        ORB_create([, nfeatures[, scaleFactor[, nlevels[, edgeThreshold[, firstLevel[, WTA_K[, scoreType[, patchSize[, fastThreshold[, blurForDescriptor]]]]]]]]]]) -> retval\n",
      "        .\n",
      "    \n",
      "    OpticalFlowDual_TVL1_create(...)\n",
      "        OpticalFlowDual_TVL1_create([, tau[, lambda[, theta[, nscales[, warps[, epsilon[, iterations[, scaleStep[, gamma[, useInitialFlow]]]]]]]]]]) -> retval\n",
      "        .\n",
      "    \n",
      "    SparsePyrLKOpticalFlow_create(...)\n",
      "        SparsePyrLKOpticalFlow_create([, winSize[, maxLevel[, iters[, useInitialFlow]]]]) -> retval\n",
      "        .\n",
      "    \n",
      "    StereoBeliefPropagation_estimateRecommendedParams(...)\n",
      "        StereoBeliefPropagation_estimateRecommendedParams(width, height, ndisp, iters, levels) -> None\n",
      "        .   @brief Uses a heuristic method to compute the recommended parameters ( ndisp, iters and levels ) for the\n",
      "        .       specified image size ( width and height ).\n",
      "    \n",
      "    StereoConstantSpaceBP_estimateRecommendedParams(...)\n",
      "        StereoConstantSpaceBP_estimateRecommendedParams(width, height, ndisp, iters, levels, nr_plane) -> None\n",
      "        .   @brief Uses a heuristic method to compute parameters (ndisp, iters, levelsand nrplane) for the specified\n",
      "        .       image size (widthand height).\n",
      "    \n",
      "    Stream_Null(...)\n",
      "        Stream_Null() -> retval\n",
      "        .   @brief Adds a callback to be called on the host after all currently enqueued items in the stream have\n",
      "        .       completed.\n",
      "        .   \n",
      "        .       @note Callbacks must not make any CUDA API calls. Callbacks must not perform any synchronization\n",
      "        .       that may depend on outstanding device work or other callbacks that are not mandated to run earlier.\n",
      "        .       Callbacks without a mandated order (in independent streams) execute in undefined order and may be\n",
      "        .       serialized.\n",
      "    \n",
      "    TargetArchs_has(...)\n",
      "        TargetArchs_has(major, minor) -> retval\n",
      "        .   @brief There is a set of methods to check whether the module contains intermediate (PTX) or binary CUDA\n",
      "        .       code for the given architecture(s):\n",
      "        .   \n",
      "        .       @param major Major compute capability version.\n",
      "        .       @param minor Minor compute capability version.\n",
      "    \n",
      "    TargetArchs_hasBin(...)\n",
      "        TargetArchs_hasBin(major, minor) -> retval\n",
      "        .\n",
      "    \n",
      "    TargetArchs_hasEqualOrGreater(...)\n",
      "        TargetArchs_hasEqualOrGreater(major, minor) -> retval\n",
      "        .\n",
      "    \n",
      "    TargetArchs_hasEqualOrGreaterBin(...)\n",
      "        TargetArchs_hasEqualOrGreaterBin(major, minor) -> retval\n",
      "        .\n",
      "    \n",
      "    TargetArchs_hasEqualOrGreaterPtx(...)\n",
      "        TargetArchs_hasEqualOrGreaterPtx(major, minor) -> retval\n",
      "        .\n",
      "    \n",
      "    TargetArchs_hasEqualOrLessPtx(...)\n",
      "        TargetArchs_hasEqualOrLessPtx(major, minor) -> retval\n",
      "        .\n",
      "    \n",
      "    TargetArchs_hasPtx(...)\n",
      "        TargetArchs_hasPtx(major, minor) -> retval\n",
      "        .\n",
      "    \n",
      "    abs(...)\n",
      "        abs(src[, dst[, stream]]) -> dst\n",
      "        .   @brief Computes an absolute value of each matrix element.\n",
      "        .   \n",
      "        .   @param src Source matrix.\n",
      "        .   @param dst Destination matrix with the same size and type as src .\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa abs\n",
      "    \n",
      "    absSum(...)\n",
      "        absSum(src[, mask]) -> retval\n",
      "        .   @brief Returns the sum of absolute values for matrix elements.\n",
      "        .   \n",
      "        .   @param src Source image of any depth except for CV_64F .\n",
      "        .   @param mask optional operation mask; it must have the same size as src1 and CV_8UC1 type.\n",
      "    \n",
      "    absdiff(...)\n",
      "        absdiff(src1, src2[, dst[, stream]]) -> dst\n",
      "        .   @brief Computes per-element absolute difference of two matrices (or of a matrix and scalar).\n",
      "        .   \n",
      "        .   @param src1 First source matrix or scalar.\n",
      "        .   @param src2 Second source matrix or scalar.\n",
      "        .   @param dst Destination matrix that has the same size and type as the input array(s).\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa absdiff\n",
      "    \n",
      "    add(...)\n",
      "        add(src1, src2[, dst[, mask[, dtype[, stream]]]]) -> dst\n",
      "        .   @brief Computes a matrix-matrix or matrix-scalar sum.\n",
      "        .   \n",
      "        .   @param src1 First source matrix or scalar.\n",
      "        .   @param src2 Second source matrix or scalar. Matrix should have the same size and type as src1 .\n",
      "        .   @param dst Destination matrix that has the same size and number of channels as the input array(s).\n",
      "        .   The depth is defined by dtype or src1 depth.\n",
      "        .   @param mask Optional operation mask, 8-bit single channel array, that specifies elements of the\n",
      "        .   destination array to be changed. The mask can be used only with single channel images.\n",
      "        .   @param dtype Optional depth of the output array.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa add\n",
      "    \n",
      "    addWeighted(...)\n",
      "        addWeighted(src1, alpha, src2, beta, gamma[, dst[, dtype[, stream]]]) -> dst\n",
      "        .   @brief Computes the weighted sum of two arrays.\n",
      "        .   \n",
      "        .   @param src1 First source array.\n",
      "        .   @param alpha Weight for the first array elements.\n",
      "        .   @param src2 Second source array of the same size and channel number as src1 .\n",
      "        .   @param beta Weight for the second array elements.\n",
      "        .   @param dst Destination array that has the same size and number of channels as the input arrays.\n",
      "        .   @param gamma Scalar added to each sum.\n",
      "        .   @param dtype Optional depth of the destination array. When both input arrays have the same depth,\n",
      "        .   dtype can be set to -1, which will be equivalent to src1.depth().\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   The function addWeighted calculates the weighted sum of two arrays as follows:\n",
      "        .   \n",
      "        .   \\f[\\texttt{dst} (I)= \\texttt{saturate} ( \\texttt{src1} (I)* \\texttt{alpha} +  \\texttt{src2} (I)* \\texttt{beta} +  \\texttt{gamma} )\\f]\n",
      "        .   \n",
      "        .   where I is a multi-dimensional index of array elements. In case of multi-channel arrays, each\n",
      "        .   channel is processed independently.\n",
      "        .   \n",
      "        .   @sa addWeighted\n",
      "    \n",
      "    alphaComp(...)\n",
      "        alphaComp(img1, img2, alpha_op[, dst[, stream]]) -> dst\n",
      "        .   @brief Composites two images using alpha opacity values contained in each image.\n",
      "        .   \n",
      "        .   @param img1 First image. Supports CV_8UC4 , CV_16UC4 , CV_32SC4 and CV_32FC4 types.\n",
      "        .   @param img2 Second image. Must have the same size and the same type as img1 .\n",
      "        .   @param dst Destination image.\n",
      "        .   @param alpha_op Flag specifying the alpha-blending operation:\n",
      "        .   -   **ALPHA_OVER**\n",
      "        .   -   **ALPHA_IN**\n",
      "        .   -   **ALPHA_OUT**\n",
      "        .   -   **ALPHA_ATOP**\n",
      "        .   -   **ALPHA_XOR**\n",
      "        .   -   **ALPHA_PLUS**\n",
      "        .   -   **ALPHA_OVER_PREMUL**\n",
      "        .   -   **ALPHA_IN_PREMUL**\n",
      "        .   -   **ALPHA_OUT_PREMUL**\n",
      "        .   -   **ALPHA_ATOP_PREMUL**\n",
      "        .   -   **ALPHA_XOR_PREMUL**\n",
      "        .   -   **ALPHA_PLUS_PREMUL**\n",
      "        .   -   **ALPHA_PREMUL**\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @note\n",
      "        .      -   An example demonstrating the use of alphaComp can be found at\n",
      "        .           opencv_source_code/samples/gpu/alpha_comp.cpp\n",
      "    \n",
      "    bilateralFilter(...)\n",
      "        bilateralFilter(src, kernel_size, sigma_color, sigma_spatial[, dst[, borderMode[, stream]]]) -> dst\n",
      "        .   @brief Performs bilateral filtering of passed image\n",
      "        .   \n",
      "        .   @param src Source image. Supports only (channels != 2 && depth() != CV_8S && depth() != CV_32S\n",
      "        .   && depth() != CV_64F).\n",
      "        .   @param dst Destination imagwe.\n",
      "        .   @param kernel_size Kernel window size.\n",
      "        .   @param sigma_color Filter sigma in the color space.\n",
      "        .   @param sigma_spatial Filter sigma in the coordinate space.\n",
      "        .   @param borderMode Border type. See borderInterpolate for details. BORDER_REFLECT101 ,\n",
      "        .   BORDER_REPLICATE , BORDER_CONSTANT , BORDER_REFLECT and BORDER_WRAP are supported for now.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa bilateralFilter\n",
      "    \n",
      "    bitwise_and(...)\n",
      "        bitwise_and(src1, src2[, dst[, mask[, stream]]]) -> dst\n",
      "        .   @brief Performs a per-element bitwise conjunction of two matrices (or of matrix and scalar).\n",
      "        .   \n",
      "        .   @param src1 First source matrix or scalar.\n",
      "        .   @param src2 Second source matrix or scalar.\n",
      "        .   @param dst Destination matrix that has the same size and type as the input array(s).\n",
      "        .   @param mask Optional operation mask, 8-bit single channel array, that specifies elements of the\n",
      "        .   destination array to be changed. The mask can be used only with single channel images.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "    \n",
      "    bitwise_not(...)\n",
      "        bitwise_not(src[, dst[, mask[, stream]]]) -> dst\n",
      "        .   @brief Performs a per-element bitwise inversion.\n",
      "        .   \n",
      "        .   @param src Source matrix.\n",
      "        .   @param dst Destination matrix with the same size and type as src .\n",
      "        .   @param mask Optional operation mask, 8-bit single channel array, that specifies elements of the\n",
      "        .   destination array to be changed. The mask can be used only with single channel images.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "    \n",
      "    bitwise_or(...)\n",
      "        bitwise_or(src1, src2[, dst[, mask[, stream]]]) -> dst\n",
      "        .   @brief Performs a per-element bitwise disjunction of two matrices (or of matrix and scalar).\n",
      "        .   \n",
      "        .   @param src1 First source matrix or scalar.\n",
      "        .   @param src2 Second source matrix or scalar.\n",
      "        .   @param dst Destination matrix that has the same size and type as the input array(s).\n",
      "        .   @param mask Optional operation mask, 8-bit single channel array, that specifies elements of the\n",
      "        .   destination array to be changed. The mask can be used only with single channel images.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "    \n",
      "    bitwise_xor(...)\n",
      "        bitwise_xor(src1, src2[, dst[, mask[, stream]]]) -> dst\n",
      "        .   @brief Performs a per-element bitwise exclusive or operation of two matrices (or of matrix and scalar).\n",
      "        .   \n",
      "        .   @param src1 First source matrix or scalar.\n",
      "        .   @param src2 Second source matrix or scalar.\n",
      "        .   @param dst Destination matrix that has the same size and type as the input array(s).\n",
      "        .   @param mask Optional operation mask, 8-bit single channel array, that specifies elements of the\n",
      "        .   destination array to be changed. The mask can be used only with single channel images.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "    \n",
      "    blendLinear(...)\n",
      "        blendLinear(img1, img2, weights1, weights2[, result[, stream]]) -> result\n",
      "        .   @brief Performs linear blending of two images.\n",
      "        .   \n",
      "        .   @param img1 First image. Supports only CV_8U and CV_32F depth.\n",
      "        .   @param img2 Second image. Must have the same size and the same type as img1 .\n",
      "        .   @param weights1 Weights for first image. Must have tha same size as img1 . Supports only CV_32F\n",
      "        .   type.\n",
      "        .   @param weights2 Weights for second image. Must have tha same size as img2 . Supports only CV_32F\n",
      "        .   type.\n",
      "        .   @param result Destination image.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "    \n",
      "    buildWarpAffineMaps(...)\n",
      "        buildWarpAffineMaps(M, inverse, dsize[, xmap[, ymap[, stream]]]) -> xmap, ymap\n",
      "        .   @brief Builds transformation maps for affine transformation.\n",
      "        .   \n",
      "        .   @param M *2x3* transformation matrix.\n",
      "        .   @param inverse Flag specifying that M is an inverse transformation ( dst=\\>src ).\n",
      "        .   @param dsize Size of the destination image.\n",
      "        .   @param xmap X values with CV_32FC1 type.\n",
      "        .   @param ymap Y values with CV_32FC1 type.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa cuda::warpAffine , cuda::remap\n",
      "    \n",
      "    buildWarpPerspectiveMaps(...)\n",
      "        buildWarpPerspectiveMaps(M, inverse, dsize[, xmap[, ymap[, stream]]]) -> xmap, ymap\n",
      "        .   @brief Builds transformation maps for perspective transformation.\n",
      "        .   \n",
      "        .   @param M *3x3* transformation matrix.\n",
      "        .   @param inverse Flag specifying that M is an inverse transformation ( dst=\\>src ).\n",
      "        .   @param dsize Size of the destination image.\n",
      "        .   @param xmap X values with CV_32FC1 type.\n",
      "        .   @param ymap Y values with CV_32FC1 type.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa cuda::warpPerspective , cuda::remap\n",
      "    \n",
      "    calcAbsSum(...)\n",
      "        calcAbsSum(src[, dst[, mask[, stream]]]) -> dst\n",
      "        .   @overload\n",
      "    \n",
      "    calcHist(...)\n",
      "        calcHist(src[, hist[, stream]]) -> hist\n",
      "        .   @brief Calculates histogram for one channel 8-bit image.\n",
      "        .   \n",
      "        .   @param src Source image with CV_8UC1 type.\n",
      "        .   @param hist Destination histogram with one row, 256 columns, and the CV_32SC1 type.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        \n",
      "        \n",
      "        \n",
      "        calcHist(src, mask[, hist[, stream]]) -> hist\n",
      "        .   @brief Calculates histogram for one channel 8-bit image confined in given mask.\n",
      "        .   \n",
      "        .   @param src Source image with CV_8UC1 type.\n",
      "        .   @param hist Destination histogram with one row, 256 columns, and the CV_32SC1 type.\n",
      "        .   @param mask A mask image same size as src and of type CV_8UC1.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "    \n",
      "    calcNorm(...)\n",
      "        calcNorm(src, normType[, dst[, mask[, stream]]]) -> dst\n",
      "        .   @overload\n",
      "    \n",
      "    calcNormDiff(...)\n",
      "        calcNormDiff(src1, src2[, dst[, normType[, stream]]]) -> dst\n",
      "        .   @overload\n",
      "    \n",
      "    calcSqrSum(...)\n",
      "        calcSqrSum(src[, dst[, mask[, stream]]]) -> dst\n",
      "        .   @overload\n",
      "    \n",
      "    calcSum(...)\n",
      "        calcSum(src[, dst[, mask[, stream]]]) -> dst\n",
      "        .   @overload\n",
      "    \n",
      "    cartToPolar(...)\n",
      "        cartToPolar(x, y[, magnitude[, angle[, angleInDegrees[, stream]]]]) -> magnitude, angle\n",
      "        .   @brief Converts Cartesian coordinates into polar.\n",
      "        .   \n",
      "        .   @param x Source matrix containing real components ( CV_32FC1 ).\n",
      "        .   @param y Source matrix containing imaginary components ( CV_32FC1 ).\n",
      "        .   @param magnitude Destination matrix of float magnitudes ( CV_32FC1 ).\n",
      "        .   @param angle Destination matrix of angles ( CV_32FC1 ).\n",
      "        .   @param angleInDegrees Flag for angles that must be evaluated in degrees.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa cartToPolar\n",
      "    \n",
      "    compare(...)\n",
      "        compare(src1, src2, cmpop[, dst[, stream]]) -> dst\n",
      "        .   @brief Compares elements of two matrices (or of a matrix and scalar).\n",
      "        .   \n",
      "        .   @param src1 First source matrix or scalar.\n",
      "        .   @param src2 Second source matrix or scalar.\n",
      "        .   @param dst Destination matrix that has the same size as the input array(s) and type CV_8U.\n",
      "        .   @param cmpop Flag specifying the relation between the elements to be checked:\n",
      "        .   -   **CMP_EQ:** a(.) == b(.)\n",
      "        .   -   **CMP_GT:** a(.) \\> b(.)\n",
      "        .   -   **CMP_GE:** a(.) \\>= b(.)\n",
      "        .   -   **CMP_LT:** a(.) \\< b(.)\n",
      "        .   -   **CMP_LE:** a(.) \\<= b(.)\n",
      "        .   -   **CMP_NE:** a(.) != b(.)\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa compare\n",
      "    \n",
      "    copyMakeBorder(...)\n",
      "        copyMakeBorder(src, top, bottom, left, right, borderType[, dst[, value[, stream]]]) -> dst\n",
      "        .   @brief Forms a border around an image.\n",
      "        .   \n",
      "        .   @param src Source image. CV_8UC1 , CV_8UC4 , CV_32SC1 , and CV_32FC1 types are supported.\n",
      "        .   @param dst Destination image with the same type as src. The size is\n",
      "        .   Size(src.cols+left+right, src.rows+top+bottom) .\n",
      "        .   @param top Number of top pixels\n",
      "        .   @param bottom Number of bottom pixels\n",
      "        .   @param left Number of left pixels\n",
      "        .   @param right Number of pixels in each direction from the source image rectangle to extrapolate.\n",
      "        .   For example: top=1, bottom=1, left=1, right=1 mean that 1 pixel-wide border needs to be built.\n",
      "        .   @param borderType Border type. See borderInterpolate for details. BORDER_REFLECT101 ,\n",
      "        .   BORDER_REPLICATE , BORDER_CONSTANT , BORDER_REFLECT and BORDER_WRAP are supported for now.\n",
      "        .   @param value Border value.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "    \n",
      "    countNonZero(...)\n",
      "        countNonZero(src) -> retval\n",
      "        .   @brief Counts non-zero matrix elements.\n",
      "        .   \n",
      "        .   @param src Single-channel source image.\n",
      "        .   \n",
      "        .   The function does not work with CV_64F images on GPUs with the compute capability \\< 1.3.\n",
      "        .   \n",
      "        .   @sa countNonZero\n",
      "        \n",
      "        \n",
      "        \n",
      "        countNonZero(src[, dst[, stream]]) -> dst\n",
      "        .   @overload\n",
      "    \n",
      "    createBackgroundSubtractorMOG(...)\n",
      "        createBackgroundSubtractorMOG([, history[, nmixtures[, backgroundRatio[, noiseSigma]]]]) -> retval\n",
      "        .   @brief Creates mixture-of-gaussian background subtractor\n",
      "        .   \n",
      "        .   @param history Length of the history.\n",
      "        .   @param nmixtures Number of Gaussian mixtures.\n",
      "        .   @param backgroundRatio Background ratio.\n",
      "        .   @param noiseSigma Noise strength (standard deviation of the brightness or each color channel). 0\n",
      "        .   means some automatic value.\n",
      "    \n",
      "    createBackgroundSubtractorMOG2(...)\n",
      "        createBackgroundSubtractorMOG2([, history[, varThreshold[, detectShadows]]]) -> retval\n",
      "        .   @brief Creates MOG2 Background Subtractor\n",
      "        .   \n",
      "        .   @param history Length of the history.\n",
      "        .   @param varThreshold Threshold on the squared Mahalanobis distance between the pixel and the model\n",
      "        .   to decide whether a pixel is well described by the background model. This parameter does not\n",
      "        .   affect the background update.\n",
      "        .   @param detectShadows If true, the algorithm will detect shadows and mark them. It decreases the\n",
      "        .   speed a bit, so if you do not need this feature, set the parameter to false.\n",
      "    \n",
      "    createBoxFilter(...)\n",
      "        createBoxFilter(srcType, dstType, ksize[, anchor[, borderMode[, borderVal]]]) -> retval\n",
      "        .   @brief Creates a normalized 2D box filter.\n",
      "        .   \n",
      "        .   @param srcType Input image type. Only CV_8UC1, CV_8UC4 and CV_32FC1 are supported for now.\n",
      "        .   @param dstType Output image type. Only the same type as src is supported for now.\n",
      "        .   @param ksize Kernel size.\n",
      "        .   @param anchor Anchor point. The default value Point(-1, -1) means that the anchor is at the kernel\n",
      "        .   center.\n",
      "        .   @param borderMode Pixel extrapolation method. For details, see borderInterpolate .\n",
      "        .   @param borderVal Default border value.\n",
      "        .   \n",
      "        .   @sa boxFilter\n",
      "    \n",
      "    createBoxMaxFilter(...)\n",
      "        createBoxMaxFilter(srcType, ksize[, anchor[, borderMode[, borderVal]]]) -> retval\n",
      "        .   @brief Creates the maximum filter.\n",
      "        .   \n",
      "        .   @param srcType Input/output image type. Only CV_8UC1 and CV_8UC4 are supported.\n",
      "        .   @param ksize Kernel size.\n",
      "        .   @param anchor Anchor point. The default value (-1) means that the anchor is at the kernel center.\n",
      "        .   @param borderMode Pixel extrapolation method. For details, see borderInterpolate .\n",
      "        .   @param borderVal Default border value.\n",
      "    \n",
      "    createBoxMinFilter(...)\n",
      "        createBoxMinFilter(srcType, ksize[, anchor[, borderMode[, borderVal]]]) -> retval\n",
      "        .   @brief Creates the minimum filter.\n",
      "        .   \n",
      "        .   @param srcType Input/output image type. Only CV_8UC1 and CV_8UC4 are supported.\n",
      "        .   @param ksize Kernel size.\n",
      "        .   @param anchor Anchor point. The default value (-1) means that the anchor is at the kernel center.\n",
      "        .   @param borderMode Pixel extrapolation method. For details, see borderInterpolate .\n",
      "        .   @param borderVal Default border value.\n",
      "    \n",
      "    createCLAHE(...)\n",
      "        createCLAHE([, clipLimit[, tileGridSize]]) -> retval\n",
      "        .   @brief Creates implementation for cuda::CLAHE .\n",
      "        .   \n",
      "        .   @param clipLimit Threshold for contrast limiting.\n",
      "        .   @param tileGridSize Size of grid for histogram equalization. Input image will be divided into\n",
      "        .   equally sized rectangular tiles. tileGridSize defines the number of tiles in row and column.\n",
      "    \n",
      "    createCannyEdgeDetector(...)\n",
      "        createCannyEdgeDetector(low_thresh, high_thresh[, apperture_size[, L2gradient]]) -> retval\n",
      "        .   @brief Creates implementation for cuda::CannyEdgeDetector .\n",
      "        .   \n",
      "        .   @param low_thresh First threshold for the hysteresis procedure.\n",
      "        .   @param high_thresh Second threshold for the hysteresis procedure.\n",
      "        .   @param apperture_size Aperture size for the Sobel operator.\n",
      "        .   @param L2gradient Flag indicating whether a more accurate \\f$L_2\\f$ norm\n",
      "        .   \\f$=\\sqrt{(dI/dx)^2 + (dI/dy)^2}\\f$ should be used to compute the image gradient magnitude (\n",
      "        .   L2gradient=true ), or a faster default \\f$L_1\\f$ norm \\f$=|dI/dx|+|dI/dy|\\f$ is enough ( L2gradient=false\n",
      "        .   ).\n",
      "    \n",
      "    createColumnSumFilter(...)\n",
      "        createColumnSumFilter(srcType, dstType, ksize[, anchor[, borderMode[, borderVal]]]) -> retval\n",
      "        .   @brief Creates a vertical 1D box filter.\n",
      "        .   \n",
      "        .   @param srcType Input image type. Only CV_8UC1 type is supported for now.\n",
      "        .   @param dstType Output image type. Only CV_32FC1 type is supported for now.\n",
      "        .   @param ksize Kernel size.\n",
      "        .   @param anchor Anchor point. The default value (-1) means that the anchor is at the kernel center.\n",
      "        .   @param borderMode Pixel extrapolation method. For details, see borderInterpolate .\n",
      "        .   @param borderVal Default border value.\n",
      "    \n",
      "    createContinuous(...)\n",
      "        createContinuous(rows, cols, type[, arr]) -> arr\n",
      "        .   @brief Creates a continuous matrix.\n",
      "        .   \n",
      "        .   @param rows Row count.\n",
      "        .   @param cols Column count.\n",
      "        .   @param type Type of the matrix.\n",
      "        .   @param arr Destination matrix. This parameter changes only if it has a proper type and area (\n",
      "        .   \\f$\\texttt{rows} \\times \\texttt{cols}\\f$ ).\n",
      "        .   \n",
      "        .   Matrix is called continuous if its elements are stored continuously, that is, without gaps at the\n",
      "        .   end of each row.\n",
      "    \n",
      "    createConvolution(...)\n",
      "        createConvolution([, user_block_size]) -> retval\n",
      "        .   @brief Creates implementation for cuda::Convolution .\n",
      "        .   \n",
      "        .   @param user_block_size Block size. If you leave default value Size(0,0) then automatic\n",
      "        .   estimation of block size will be used (which is optimized for speed). By varying user_block_size\n",
      "        .   you can reduce memory requirements at the cost of speed.\n",
      "    \n",
      "    createDFT(...)\n",
      "        createDFT(dft_size, flags) -> retval\n",
      "        .   @brief Creates implementation for cuda::DFT.\n",
      "        .   \n",
      "        .   @param dft_size The image size.\n",
      "        .   @param flags Optional flags:\n",
      "        .   -   **DFT_ROWS** transforms each individual row of the source matrix.\n",
      "        .   -   **DFT_SCALE** scales the result: divide it by the number of elements in the transform\n",
      "        .   (obtained from dft_size ).\n",
      "        .   -   **DFT_INVERSE** inverts DFT. Use for complex-complex cases (real-complex and complex-real\n",
      "        .   cases are always forward and inverse, respectively).\n",
      "        .   -   **DFT_COMPLEX_INPUT** Specifies that inputs will be complex with 2 channels.\n",
      "        .   -   **DFT_REAL_OUTPUT** specifies the output as real. The source matrix is the result of\n",
      "        .   real-complex transform, so the destination matrix must be real.\n",
      "    \n",
      "    createDerivFilter(...)\n",
      "        createDerivFilter(srcType, dstType, dx, dy, ksize[, normalize[, scale[, rowBorderMode[, columnBorderMode]]]]) -> retval\n",
      "        .   @brief Creates a generalized Deriv operator.\n",
      "        .   \n",
      "        .   @param srcType Source image type.\n",
      "        .   @param dstType Destination array type.\n",
      "        .   @param dx Derivative order in respect of x.\n",
      "        .   @param dy Derivative order in respect of y.\n",
      "        .   @param ksize Aperture size. See getDerivKernels for details.\n",
      "        .   @param normalize Flag indicating whether to normalize (scale down) the filter coefficients or not.\n",
      "        .   See getDerivKernels for details.\n",
      "        .   @param scale Optional scale factor for the computed derivative values. By default, no scaling is\n",
      "        .   applied. For details, see getDerivKernels .\n",
      "        .   @param rowBorderMode Pixel extrapolation method in the vertical direction. For details, see\n",
      "        .   borderInterpolate.\n",
      "        .   @param columnBorderMode Pixel extrapolation method in the horizontal direction.\n",
      "    \n",
      "    createDisparityBilateralFilter(...)\n",
      "        createDisparityBilateralFilter([, ndisp[, radius[, iters]]]) -> retval\n",
      "        .   @brief Creates DisparityBilateralFilter object.\n",
      "        .   \n",
      "        .   @param ndisp Number of disparities.\n",
      "        .   @param radius Filter radius.\n",
      "        .   @param iters Number of iterations.\n",
      "    \n",
      "    createGaussianFilter(...)\n",
      "        createGaussianFilter(srcType, dstType, ksize, sigma1[, sigma2[, rowBorderMode[, columnBorderMode]]]) -> retval\n",
      "        .   @brief Creates a Gaussian filter.\n",
      "        .   \n",
      "        .   @param srcType Source image type.\n",
      "        .   @param dstType Destination array type.\n",
      "        .   @param ksize Aperture size. See getGaussianKernel for details.\n",
      "        .   @param sigma1 Gaussian sigma in the horizontal direction. See getGaussianKernel for details.\n",
      "        .   @param sigma2 Gaussian sigma in the vertical direction. If 0, then\n",
      "        .   \\f$\\texttt{sigma2}\\leftarrow\\texttt{sigma1}\\f$ .\n",
      "        .   @param rowBorderMode Pixel extrapolation method in the vertical direction. For details, see\n",
      "        .   borderInterpolate.\n",
      "        .   @param columnBorderMode Pixel extrapolation method in the horizontal direction.\n",
      "        .   \n",
      "        .   @sa GaussianBlur\n",
      "    \n",
      "    createGeneralizedHoughBallard(...)\n",
      "        createGeneralizedHoughBallard() -> retval\n",
      "        .   @brief Creates implementation for generalized hough transform from @cite Ballard1981 .\n",
      "    \n",
      "    createGeneralizedHoughGuil(...)\n",
      "        createGeneralizedHoughGuil() -> retval\n",
      "        .   @brief Creates implementation for generalized hough transform from @cite Guil1999 .\n",
      "    \n",
      "    createGoodFeaturesToTrackDetector(...)\n",
      "        createGoodFeaturesToTrackDetector(srcType[, maxCorners[, qualityLevel[, minDistance[, blockSize[, useHarrisDetector[, harrisK]]]]]]) -> retval\n",
      "        .   @brief Creates implementation for cuda::CornersDetector .\n",
      "        .   \n",
      "        .   @param srcType Input source type. Only CV_8UC1 and CV_32FC1 are supported for now.\n",
      "        .   @param maxCorners Maximum number of corners to return. If there are more corners than are found,\n",
      "        .   the strongest of them is returned.\n",
      "        .   @param qualityLevel Parameter characterizing the minimal accepted quality of image corners. The\n",
      "        .   parameter value is multiplied by the best corner quality measure, which is the minimal eigenvalue\n",
      "        .   (see cornerMinEigenVal ) or the Harris function response (see cornerHarris ). The corners with the\n",
      "        .   quality measure less than the product are rejected. For example, if the best corner has the\n",
      "        .   quality measure = 1500, and the qualityLevel=0.01 , then all the corners with the quality measure\n",
      "        .   less than 15 are rejected.\n",
      "        .   @param minDistance Minimum possible Euclidean distance between the returned corners.\n",
      "        .   @param blockSize Size of an average block for computing a derivative covariation matrix over each\n",
      "        .   pixel neighborhood. See cornerEigenValsAndVecs .\n",
      "        .   @param useHarrisDetector Parameter indicating whether to use a Harris detector (see cornerHarris)\n",
      "        .   or cornerMinEigenVal.\n",
      "        .   @param harrisK Free parameter of the Harris detector.\n",
      "    \n",
      "    createHarrisCorner(...)\n",
      "        createHarrisCorner(srcType, blockSize, ksize, k[, borderType]) -> retval\n",
      "        .   @brief Creates implementation for Harris cornerness criteria.\n",
      "        .   \n",
      "        .   @param srcType Input source type. Only CV_8UC1 and CV_32FC1 are supported for now.\n",
      "        .   @param blockSize Neighborhood size.\n",
      "        .   @param ksize Aperture parameter for the Sobel operator.\n",
      "        .   @param k Harris detector free parameter.\n",
      "        .   @param borderType Pixel extrapolation method. Only BORDER_REFLECT101 and BORDER_REPLICATE are\n",
      "        .   supported for now.\n",
      "        .   \n",
      "        .   @sa cornerHarris\n",
      "    \n",
      "    createHoughCirclesDetector(...)\n",
      "        createHoughCirclesDetector(dp, minDist, cannyThreshold, votesThreshold, minRadius, maxRadius[, maxCircles]) -> retval\n",
      "        .   @brief Creates implementation for cuda::HoughCirclesDetector .\n",
      "        .   \n",
      "        .   @param dp Inverse ratio of the accumulator resolution to the image resolution. For example, if\n",
      "        .   dp=1 , the accumulator has the same resolution as the input image. If dp=2 , the accumulator has\n",
      "        .   half as big width and height.\n",
      "        .   @param minDist Minimum distance between the centers of the detected circles. If the parameter is\n",
      "        .   too small, multiple neighbor circles may be falsely detected in addition to a true one. If it is\n",
      "        .   too large, some circles may be missed.\n",
      "        .   @param cannyThreshold The higher threshold of the two passed to Canny edge detector (the lower one\n",
      "        .   is twice smaller).\n",
      "        .   @param votesThreshold The accumulator threshold for the circle centers at the detection stage. The\n",
      "        .   smaller it is, the more false circles may be detected.\n",
      "        .   @param minRadius Minimum circle radius.\n",
      "        .   @param maxRadius Maximum circle radius.\n",
      "        .   @param maxCircles Maximum number of output circles.\n",
      "    \n",
      "    createHoughLinesDetector(...)\n",
      "        createHoughLinesDetector(rho, theta, threshold[, doSort[, maxLines]]) -> retval\n",
      "        .   @brief Creates implementation for cuda::HoughLinesDetector .\n",
      "        .   \n",
      "        .   @param rho Distance resolution of the accumulator in pixels.\n",
      "        .   @param theta Angle resolution of the accumulator in radians.\n",
      "        .   @param threshold Accumulator threshold parameter. Only those lines are returned that get enough\n",
      "        .   votes ( \\f$>\\texttt{threshold}\\f$ ).\n",
      "        .   @param doSort Performs lines sort by votes.\n",
      "        .   @param maxLines Maximum number of output lines.\n",
      "    \n",
      "    createHoughSegmentDetector(...)\n",
      "        createHoughSegmentDetector(rho, theta, minLineLength, maxLineGap[, maxLines]) -> retval\n",
      "        .   @brief Creates implementation for cuda::HoughSegmentDetector .\n",
      "        .   \n",
      "        .   @param rho Distance resolution of the accumulator in pixels.\n",
      "        .   @param theta Angle resolution of the accumulator in radians.\n",
      "        .   @param minLineLength Minimum line length. Line segments shorter than that are rejected.\n",
      "        .   @param maxLineGap Maximum allowed gap between points on the same line to link them.\n",
      "        .   @param maxLines Maximum number of output lines.\n",
      "    \n",
      "    createLaplacianFilter(...)\n",
      "        createLaplacianFilter(srcType, dstType[, ksize[, scale[, borderMode[, borderVal]]]]) -> retval\n",
      "        .   @brief Creates a Laplacian operator.\n",
      "        .   \n",
      "        .   @param srcType Input image type. Supports CV_8U , CV_16U and CV_32F one and four channel image.\n",
      "        .   @param dstType Output image type. Only the same type as src is supported for now.\n",
      "        .   @param ksize Aperture size used to compute the second-derivative filters (see getDerivKernels). It\n",
      "        .   must be positive and odd. Only ksize = 1 and ksize = 3 are supported.\n",
      "        .   @param scale Optional scale factor for the computed Laplacian values. By default, no scaling is\n",
      "        .   applied (see getDerivKernels ).\n",
      "        .   @param borderMode Pixel extrapolation method. For details, see borderInterpolate .\n",
      "        .   @param borderVal Default border value.\n",
      "        .   \n",
      "        .   @sa Laplacian\n",
      "    \n",
      "    createLinearFilter(...)\n",
      "        createLinearFilter(srcType, dstType, kernel[, anchor[, borderMode[, borderVal]]]) -> retval\n",
      "        .   @brief Creates a non-separable linear 2D filter.\n",
      "        .   \n",
      "        .   @param srcType Input image type. Supports CV_8U , CV_16U and CV_32F one and four channel image.\n",
      "        .   @param dstType Output image type. Only the same type as src is supported for now.\n",
      "        .   @param kernel 2D array of filter coefficients.\n",
      "        .   @param anchor Anchor point. The default value Point(-1, -1) means that the anchor is at the kernel\n",
      "        .   center.\n",
      "        .   @param borderMode Pixel extrapolation method. For details, see borderInterpolate .\n",
      "        .   @param borderVal Default border value.\n",
      "        .   \n",
      "        .   @sa filter2D\n",
      "    \n",
      "    createLookUpTable(...)\n",
      "        createLookUpTable(lut) -> retval\n",
      "        .   @brief Creates implementation for cuda::LookUpTable .\n",
      "        .   \n",
      "        .   @param lut Look-up table of 256 elements. It is a continuous CV_8U matrix.\n",
      "    \n",
      "    createMedianFilter(...)\n",
      "        createMedianFilter(srcType, windowSize[, partition]) -> retval\n",
      "        .   @brief Performs median filtering for each point of the source image.\n",
      "        .   \n",
      "        .   @param srcType type of of source image. Only CV_8UC1 images are supported for now.\n",
      "        .   @param windowSize Size of the kernerl used for the filtering. Uses a (windowSize x windowSize) filter.\n",
      "        .   @param partition Specifies the parallel granularity of the workload. This parameter should be used GPU experts when optimizing performance.\n",
      "        .   \n",
      "        .   Outputs an image that has been filtered using median-filtering formulation.\n",
      "    \n",
      "    createMinEigenValCorner(...)\n",
      "        createMinEigenValCorner(srcType, blockSize, ksize[, borderType]) -> retval\n",
      "        .   @brief Creates implementation for the minimum eigen value of a 2x2 derivative covariation matrix (the\n",
      "        .   cornerness criteria).\n",
      "        .   \n",
      "        .   @param srcType Input source type. Only CV_8UC1 and CV_32FC1 are supported for now.\n",
      "        .   @param blockSize Neighborhood size.\n",
      "        .   @param ksize Aperture parameter for the Sobel operator.\n",
      "        .   @param borderType Pixel extrapolation method. Only BORDER_REFLECT101 and BORDER_REPLICATE are\n",
      "        .   supported for now.\n",
      "        .   \n",
      "        .   @sa cornerMinEigenVal\n",
      "    \n",
      "    createMorphologyFilter(...)\n",
      "        createMorphologyFilter(op, srcType, kernel[, anchor[, iterations]]) -> retval\n",
      "        .   @brief Creates a 2D morphological filter.\n",
      "        .   \n",
      "        .   @param op Type of morphological operation. The following types are possible:\n",
      "        .   -   **MORPH_ERODE** erode\n",
      "        .   -   **MORPH_DILATE** dilate\n",
      "        .   -   **MORPH_OPEN** opening\n",
      "        .   -   **MORPH_CLOSE** closing\n",
      "        .   -   **MORPH_GRADIENT** morphological gradient\n",
      "        .   -   **MORPH_TOPHAT** \"top hat\"\n",
      "        .   -   **MORPH_BLACKHAT** \"black hat\"\n",
      "        .   @param srcType Input/output image type. Only CV_8UC1, CV_8UC4, CV_32FC1 and CV_32FC4 are supported.\n",
      "        .   @param kernel 2D 8-bit structuring element for the morphological operation.\n",
      "        .   @param anchor Anchor position within the structuring element. Negative values mean that the anchor\n",
      "        .   is at the center.\n",
      "        .   @param iterations Number of times erosion and dilation to be applied.\n",
      "        .   \n",
      "        .   @sa morphologyEx\n",
      "    \n",
      "    createRowSumFilter(...)\n",
      "        createRowSumFilter(srcType, dstType, ksize[, anchor[, borderMode[, borderVal]]]) -> retval\n",
      "        .   @brief Creates a horizontal 1D box filter.\n",
      "        .   \n",
      "        .   @param srcType Input image type. Only CV_8UC1 type is supported for now.\n",
      "        .   @param dstType Output image type. Only CV_32FC1 type is supported for now.\n",
      "        .   @param ksize Kernel size.\n",
      "        .   @param anchor Anchor point. The default value (-1) means that the anchor is at the kernel center.\n",
      "        .   @param borderMode Pixel extrapolation method. For details, see borderInterpolate .\n",
      "        .   @param borderVal Default border value.\n",
      "    \n",
      "    createScharrFilter(...)\n",
      "        createScharrFilter(srcType, dstType, dx, dy[, scale[, rowBorderMode[, columnBorderMode]]]) -> retval\n",
      "        .   @brief Creates a vertical or horizontal Scharr operator.\n",
      "        .   \n",
      "        .   @param srcType Source image type.\n",
      "        .   @param dstType Destination array type.\n",
      "        .   @param dx Order of the derivative x.\n",
      "        .   @param dy Order of the derivative y.\n",
      "        .   @param scale Optional scale factor for the computed derivative values. By default, no scaling is\n",
      "        .   applied. See getDerivKernels for details.\n",
      "        .   @param rowBorderMode Pixel extrapolation method in the vertical direction. For details, see\n",
      "        .   borderInterpolate.\n",
      "        .   @param columnBorderMode Pixel extrapolation method in the horizontal direction.\n",
      "        .   \n",
      "        .   @sa Scharr\n",
      "    \n",
      "    createSeparableLinearFilter(...)\n",
      "        createSeparableLinearFilter(srcType, dstType, rowKernel, columnKernel[, anchor[, rowBorderMode[, columnBorderMode]]]) -> retval\n",
      "        .   @brief Creates a separable linear filter.\n",
      "        .   \n",
      "        .   @param srcType Source array type.\n",
      "        .   @param dstType Destination array type.\n",
      "        .   @param rowKernel Horizontal filter coefficients. Support kernels with size \\<= 32 .\n",
      "        .   @param columnKernel Vertical filter coefficients. Support kernels with size \\<= 32 .\n",
      "        .   @param anchor Anchor position within the kernel. Negative values mean that anchor is positioned at\n",
      "        .   the aperture center.\n",
      "        .   @param rowBorderMode Pixel extrapolation method in the vertical direction For details, see\n",
      "        .   borderInterpolate.\n",
      "        .   @param columnBorderMode Pixel extrapolation method in the horizontal direction.\n",
      "        .   \n",
      "        .   @sa sepFilter2D\n",
      "    \n",
      "    createSobelFilter(...)\n",
      "        createSobelFilter(srcType, dstType, dx, dy[, ksize[, scale[, rowBorderMode[, columnBorderMode]]]]) -> retval\n",
      "        .   @brief Creates a Sobel operator.\n",
      "        .   \n",
      "        .   @param srcType Source image type.\n",
      "        .   @param dstType Destination array type.\n",
      "        .   @param dx Derivative order in respect of x.\n",
      "        .   @param dy Derivative order in respect of y.\n",
      "        .   @param ksize Size of the extended Sobel kernel. Possible values are 1, 3, 5 or 7.\n",
      "        .   @param scale Optional scale factor for the computed derivative values. By default, no scaling is\n",
      "        .   applied. For details, see getDerivKernels .\n",
      "        .   @param rowBorderMode Pixel extrapolation method in the vertical direction. For details, see\n",
      "        .   borderInterpolate.\n",
      "        .   @param columnBorderMode Pixel extrapolation method in the horizontal direction.\n",
      "        .   \n",
      "        .   @sa Sobel\n",
      "    \n",
      "    createStereoBM(...)\n",
      "        createStereoBM([, numDisparities[, blockSize]]) -> retval\n",
      "        .   @brief Creates StereoBM object.\n",
      "        .   \n",
      "        .   @param numDisparities the disparity search range. For each pixel algorithm will find the best\n",
      "        .   disparity from 0 (default minimum disparity) to numDisparities. The search range can then be\n",
      "        .   shifted by changing the minimum disparity.\n",
      "        .   @param blockSize the linear size of the blocks compared by the algorithm. The size should be odd\n",
      "        .   (as the block is centered at the current pixel). Larger block size implies smoother, though less\n",
      "        .   accurate disparity map. Smaller block size gives more detailed disparity map, but there is higher\n",
      "        .   chance for algorithm to find a wrong correspondence.\n",
      "    \n",
      "    createStereoBeliefPropagation(...)\n",
      "        createStereoBeliefPropagation([, ndisp[, iters[, levels[, msg_type]]]]) -> retval\n",
      "        .   @brief Creates StereoBeliefPropagation object.\n",
      "        .   \n",
      "        .   @param ndisp Number of disparities.\n",
      "        .   @param iters Number of BP iterations on each level.\n",
      "        .   @param levels Number of levels.\n",
      "        .   @param msg_type Type for messages. CV_16SC1 and CV_32FC1 types are supported.\n",
      "    \n",
      "    createStereoConstantSpaceBP(...)\n",
      "        createStereoConstantSpaceBP([, ndisp[, iters[, levels[, nr_plane[, msg_type]]]]]) -> retval\n",
      "        .   @brief Creates StereoConstantSpaceBP object.\n",
      "        .   \n",
      "        .   @param ndisp Number of disparities.\n",
      "        .   @param iters Number of BP iterations on each level.\n",
      "        .   @param levels Number of levels.\n",
      "        .   @param nr_plane Number of disparity levels on the first level.\n",
      "        .   @param msg_type Type for messages. CV_16SC1 and CV_32FC1 types are supported.\n",
      "    \n",
      "    createTemplateMatching(...)\n",
      "        createTemplateMatching(srcType, method[, user_block_size]) -> retval\n",
      "        .   @brief Creates implementation for cuda::TemplateMatching .\n",
      "        .   \n",
      "        .   @param srcType Input source type. CV_32F and CV_8U depth images (1..4 channels) are supported\n",
      "        .   for now.\n",
      "        .   @param method Specifies the way to compare the template with the image.\n",
      "        .   @param user_block_size You can use field user_block_size to set specific block size. If you\n",
      "        .   leave its default value Size(0,0) then automatic estimation of block size will be used (which is\n",
      "        .   optimized for speed). By varying user_block_size you can reduce memory requirements at the cost\n",
      "        .   of speed.\n",
      "        .   \n",
      "        .   The following methods are supported for the CV_8U depth images for now:\n",
      "        .   \n",
      "        .   -   CV_TM_SQDIFF\n",
      "        .   -   CV_TM_SQDIFF_NORMED\n",
      "        .   -   CV_TM_CCORR\n",
      "        .   -   CV_TM_CCORR_NORMED\n",
      "        .   -   CV_TM_CCOEFF\n",
      "        .   -   CV_TM_CCOEFF_NORMED\n",
      "        .   \n",
      "        .   The following methods are supported for the CV_32F images for now:\n",
      "        .   \n",
      "        .   -   CV_TM_SQDIFF\n",
      "        .   -   CV_TM_CCORR\n",
      "        .   \n",
      "        .   @sa matchTemplate\n",
      "    \n",
      "    cvtColor(...)\n",
      "        cvtColor(src, code[, dst[, dcn[, stream]]]) -> dst\n",
      "        .   @brief Converts an image from one color space to another.\n",
      "        .   \n",
      "        .   @param src Source image with CV_8U , CV_16U , or CV_32F depth and 1, 3, or 4 channels.\n",
      "        .   @param dst Destination image.\n",
      "        .   @param code Color space conversion code. For details, see cvtColor .\n",
      "        .   @param dcn Number of channels in the destination image. If the parameter is 0, the number of the\n",
      "        .   channels is derived automatically from src and the code .\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   3-channel color spaces (like HSV, XYZ, and so on) can be stored in a 4-channel image for better\n",
      "        .   performance.\n",
      "        .   \n",
      "        .   @sa cvtColor\n",
      "    \n",
      "    demosaicing(...)\n",
      "        demosaicing(src, code[, dst[, dcn[, stream]]]) -> dst\n",
      "        .   @brief Converts an image from Bayer pattern to RGB or grayscale.\n",
      "        .   \n",
      "        .   @param src Source image (8-bit or 16-bit single channel).\n",
      "        .   @param dst Destination image.\n",
      "        .   @param code Color space conversion code (see the description below).\n",
      "        .   @param dcn Number of channels in the destination image. If the parameter is 0, the number of the\n",
      "        .   channels is derived automatically from src and the code .\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   The function can do the following transformations:\n",
      "        .   \n",
      "        .   -   Demosaicing using bilinear interpolation\n",
      "        .   \n",
      "        .       > -   COLOR_BayerBG2GRAY , COLOR_BayerGB2GRAY , COLOR_BayerRG2GRAY , COLOR_BayerGR2GRAY\n",
      "        .       > -   COLOR_BayerBG2BGR , COLOR_BayerGB2BGR , COLOR_BayerRG2BGR , COLOR_BayerGR2BGR\n",
      "        .   \n",
      "        .   -   Demosaicing using Malvar-He-Cutler algorithm (@cite MHT2011)\n",
      "        .   \n",
      "        .       > -   COLOR_BayerBG2GRAY_MHT , COLOR_BayerGB2GRAY_MHT , COLOR_BayerRG2GRAY_MHT ,\n",
      "        .       >     COLOR_BayerGR2GRAY_MHT\n",
      "        .       > -   COLOR_BayerBG2BGR_MHT , COLOR_BayerGB2BGR_MHT , COLOR_BayerRG2BGR_MHT ,\n",
      "        .       >     COLOR_BayerGR2BGR_MHT\n",
      "        .   \n",
      "        .   @sa cvtColor\n",
      "    \n",
      "    dft(...)\n",
      "        dft(src, dft_size[, dst[, flags[, stream]]]) -> dst\n",
      "        .   @brief Performs a forward or inverse discrete Fourier transform (1D or 2D) of the floating point matrix.\n",
      "        .   \n",
      "        .   @param src Source matrix (real or complex).\n",
      "        .   @param dst Destination matrix (real or complex).\n",
      "        .   @param dft_size Size of a discrete Fourier transform.\n",
      "        .   @param flags Optional flags:\n",
      "        .   -   **DFT_ROWS** transforms each individual row of the source matrix.\n",
      "        .   -   **DFT_SCALE** scales the result: divide it by the number of elements in the transform\n",
      "        .   (obtained from dft_size ).\n",
      "        .   -   **DFT_INVERSE** inverts DFT. Use for complex-complex cases (real-complex and complex-real\n",
      "        .   cases are always forward and inverse, respectively).\n",
      "        .   -   **DFT_COMPLEX_INPUT** Specifies that input is complex input with 2 channels.\n",
      "        .   -   **DFT_REAL_OUTPUT** specifies the output as real. The source matrix is the result of\n",
      "        .   real-complex transform, so the destination matrix must be real.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   Use to handle real matrices ( CV32FC1 ) and complex matrices in the interleaved format ( CV32FC2 ).\n",
      "        .   \n",
      "        .   The source matrix should be continuous, otherwise reallocation and data copying is performed. The\n",
      "        .   function chooses an operation mode depending on the flags, size, and channel count of the source\n",
      "        .   matrix:\n",
      "        .   \n",
      "        .   -   If the source matrix is complex and the output is not specified as real, the destination\n",
      "        .   matrix is complex and has the dft_size size and CV_32FC2 type. The destination matrix\n",
      "        .   contains a full result of the DFT (forward or inverse).\n",
      "        .   -   If the source matrix is complex and the output is specified as real, the function assumes that\n",
      "        .   its input is the result of the forward transform (see the next item). The destination matrix\n",
      "        .   has the dft_size size and CV_32FC1 type. It contains the result of the inverse DFT.\n",
      "        .   -   If the source matrix is real (its type is CV_32FC1 ), forward DFT is performed. The result of\n",
      "        .   the DFT is packed into complex ( CV_32FC2 ) matrix. So, the width of the destination matrix\n",
      "        .   is dft_size.width / 2 + 1 . But if the source is a single column, the height is reduced\n",
      "        .   instead of the width.\n",
      "        .   \n",
      "        .   @sa dft\n",
      "    \n",
      "    divide(...)\n",
      "        divide(src1, src2[, dst[, scale[, dtype[, stream]]]]) -> dst\n",
      "        .   @brief Computes a matrix-matrix or matrix-scalar division.\n",
      "        .   \n",
      "        .   @param src1 First source matrix or a scalar.\n",
      "        .   @param src2 Second source matrix or scalar.\n",
      "        .   @param dst Destination matrix that has the same size and number of channels as the input array(s).\n",
      "        .   The depth is defined by dtype or src1 depth.\n",
      "        .   @param scale Optional scale factor.\n",
      "        .   @param dtype Optional depth of the output array.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   This function, in contrast to divide, uses a round-down rounding mode.\n",
      "        .   \n",
      "        .   @sa divide\n",
      "    \n",
      "    drawColorDisp(...)\n",
      "        drawColorDisp(src_disp, ndisp[, dst_disp[, stream]]) -> dst_disp\n",
      "        .   @brief Colors a disparity image.\n",
      "        .   \n",
      "        .   @param src_disp Input single-channel 8-bit unsigned, 16-bit signed, 32-bit signed or 32-bit\n",
      "        .   floating-point disparity image. If 16-bit signed format is used, the values are assumed to have no\n",
      "        .   fractional bits.\n",
      "        .   @param dst_disp Output disparity image. It has the same size as src_disp. The type is CV_8UC4\n",
      "        .   in BGRA format (alpha = 255).\n",
      "        .   @param ndisp Number of disparities.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   This function draws a colored disparity map by converting disparity values from [0..ndisp) interval\n",
      "        .   first to HSV color space (where different disparity values correspond to different hues) and then\n",
      "        .   converting the pixels to RGB for visualization.\n",
      "    \n",
      "    ensureSizeIsEnough(...)\n",
      "        ensureSizeIsEnough(rows, cols, type[, arr]) -> arr\n",
      "        .   @brief Ensures that the size of a matrix is big enough and the matrix has a proper type.\n",
      "        .   \n",
      "        .   @param rows Minimum desired number of rows.\n",
      "        .   @param cols Minimum desired number of columns.\n",
      "        .   @param type Desired matrix type.\n",
      "        .   @param arr Destination matrix.\n",
      "        .   \n",
      "        .   The function does not reallocate memory if the matrix has proper attributes already.\n",
      "    \n",
      "    equalizeHist(...)\n",
      "        equalizeHist(src[, dst[, stream]]) -> dst\n",
      "        .   @brief Equalizes the histogram of a grayscale image.\n",
      "        .   \n",
      "        .   @param src Source image with CV_8UC1 type.\n",
      "        .   @param dst Destination image.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa equalizeHist\n",
      "    \n",
      "    evenLevels(...)\n",
      "        evenLevels(nLevels, lowerLevel, upperLevel[, levels[, stream]]) -> levels\n",
      "        .   @brief Computes levels with even distribution.\n",
      "        .   \n",
      "        .   @param levels Destination array. levels has 1 row, nLevels columns, and the CV_32SC1 type.\n",
      "        .   @param nLevels Number of computed levels. nLevels must be at least 2.\n",
      "        .   @param lowerLevel Lower boundary value of the lowest level.\n",
      "        .   @param upperLevel Upper boundary value of the greatest level.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "    \n",
      "    exp(...)\n",
      "        exp(src[, dst[, stream]]) -> dst\n",
      "        .   @brief Computes an exponent of each matrix element.\n",
      "        .   \n",
      "        .   @param src Source matrix.\n",
      "        .   @param dst Destination matrix with the same size and type as src .\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa exp\n",
      "    \n",
      "    findMinMax(...)\n",
      "        findMinMax(src[, dst[, mask[, stream]]]) -> dst\n",
      "        .   @overload\n",
      "    \n",
      "    findMinMaxLoc(...)\n",
      "        findMinMaxLoc(src[, minMaxVals[, loc[, mask[, stream]]]]) -> minMaxVals, loc\n",
      "        .   @overload\n",
      "    \n",
      "    flip(...)\n",
      "        flip(src, flipCode[, dst[, stream]]) -> dst\n",
      "        .   @brief Flips a 2D matrix around vertical, horizontal, or both axes.\n",
      "        .   \n",
      "        .   @param src Source matrix. Supports 1, 3 and 4 channels images with CV_8U, CV_16U, CV_32S or\n",
      "        .   CV_32F depth.\n",
      "        .   @param dst Destination matrix.\n",
      "        .   @param flipCode Flip mode for the source:\n",
      "        .   -   0 Flips around x-axis.\n",
      "        .   -   \\> 0 Flips around y-axis.\n",
      "        .   -   \\< 0 Flips around both axes.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa flip\n",
      "    \n",
      "    gammaCorrection(...)\n",
      "        gammaCorrection(src[, dst[, forward[, stream]]]) -> dst\n",
      "        .   @brief Routines for correcting image color gamma.\n",
      "        .   \n",
      "        .   @param src Source image (3- or 4-channel 8 bit).\n",
      "        .   @param dst Destination image.\n",
      "        .   @param forward true for forward gamma correction or false for inverse gamma correction.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "    \n",
      "    gemm(...)\n",
      "        gemm(src1, src2, alpha, src3, beta[, dst[, flags[, stream]]]) -> dst\n",
      "        .   @brief Performs generalized matrix multiplication.\n",
      "        .   \n",
      "        .   @param src1 First multiplied input matrix that should have CV_32FC1 , CV_64FC1 , CV_32FC2 , or\n",
      "        .   CV_64FC2 type.\n",
      "        .   @param src2 Second multiplied input matrix of the same type as src1 .\n",
      "        .   @param alpha Weight of the matrix product.\n",
      "        .   @param src3 Third optional delta matrix added to the matrix product. It should have the same type\n",
      "        .   as src1 and src2 .\n",
      "        .   @param beta Weight of src3 .\n",
      "        .   @param dst Destination matrix. It has the proper size and the same type as input matrices.\n",
      "        .   @param flags Operation flags:\n",
      "        .   -   **GEMM_1_T** transpose src1\n",
      "        .   -   **GEMM_2_T** transpose src2\n",
      "        .   -   **GEMM_3_T** transpose src3\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   The function performs generalized matrix multiplication similar to the gemm functions in BLAS level\n",
      "        .   3. For example, gemm(src1, src2, alpha, src3, beta, dst, GEMM_1_T + GEMM_3_T) corresponds to\n",
      "        .   \n",
      "        .   \\f[\\texttt{dst} =  \\texttt{alpha} \\cdot \\texttt{src1} ^T  \\cdot \\texttt{src2} +  \\texttt{beta} \\cdot \\texttt{src3} ^T\\f]\n",
      "        .   \n",
      "        .   @note Transposition operation doesn't support CV_64FC2 input type.\n",
      "        .   \n",
      "        .   @sa gemm\n",
      "    \n",
      "    getCudaEnabledDeviceCount(...)\n",
      "        getCudaEnabledDeviceCount() -> retval\n",
      "        .   @brief Returns the number of installed CUDA-enabled devices.\n",
      "        .   \n",
      "        .   Use this function before any other CUDA functions calls. If OpenCV is compiled without CUDA support,\n",
      "        .   this function returns 0. If the CUDA driver is not installed, or is incompatible, this function\n",
      "        .   returns -1.\n",
      "    \n",
      "    getDevice(...)\n",
      "        getDevice() -> retval\n",
      "        .   @brief Returns the current device index set by cuda::setDevice or initialized by default.\n",
      "    \n",
      "    histEven(...)\n",
      "        histEven(src, histSize, lowerLevel, upperLevel[, hist[, stream]]) -> hist\n",
      "        .   @brief Calculates a histogram with evenly distributed bins.\n",
      "        .   \n",
      "        .   @param src Source image. CV_8U, CV_16U, or CV_16S depth and 1 or 4 channels are supported. For\n",
      "        .   a four-channel image, all channels are processed separately.\n",
      "        .   @param hist Destination histogram with one row, histSize columns, and the CV_32S type.\n",
      "        .   @param histSize Size of the histogram.\n",
      "        .   @param lowerLevel Lower boundary of lowest-level bin.\n",
      "        .   @param upperLevel Upper boundary of highest-level bin.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        \n",
      "        \n",
      "        \n",
      "        histEven(src, hist, histSize, lowerLevel, upperLevel[, stream]) -> None\n",
      "        .   @overload\n",
      "    \n",
      "    histRange(...)\n",
      "        histRange(src, levels[, hist[, stream]]) -> hist\n",
      "        .   @brief Calculates a histogram with bins determined by the levels array.\n",
      "        .   \n",
      "        .   @param src Source image. CV_8U , CV_16U , or CV_16S depth and 1 or 4 channels are supported.\n",
      "        .   For a four-channel image, all channels are processed separately.\n",
      "        .   @param hist Destination histogram with one row, (levels.cols-1) columns, and the CV_32SC1 type.\n",
      "        .   @param levels Number of levels in the histogram.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        \n",
      "        \n",
      "        \n",
      "        histRange(src, hist, levels[, stream]) -> None\n",
      "        .   @overload\n",
      "    \n",
      "    integral(...)\n",
      "        integral(src[, sum[, stream]]) -> sum\n",
      "        .   @brief Computes an integral image.\n",
      "        .   \n",
      "        .   @param src Source image. Only CV_8UC1 images are supported for now.\n",
      "        .   @param sum Integral image containing 32-bit unsigned integer values packed into CV_32SC1 .\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa integral\n",
      "    \n",
      "    log(...)\n",
      "        log(src[, dst[, stream]]) -> dst\n",
      "        .   @brief Computes a natural logarithm of absolute value of each matrix element.\n",
      "        .   \n",
      "        .   @param src Source matrix.\n",
      "        .   @param dst Destination matrix with the same size and type as src .\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa log\n",
      "    \n",
      "    magnitude(...)\n",
      "        magnitude(xy[, magnitude[, stream]]) -> magnitude\n",
      "        .   @brief Computes magnitudes of complex matrix elements.\n",
      "        .   \n",
      "        .   @param xy Source complex matrix in the interleaved format ( CV_32FC2 ).\n",
      "        .   @param magnitude Destination matrix of float magnitudes ( CV_32FC1 ).\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa magnitude\n",
      "        \n",
      "        \n",
      "        \n",
      "        magnitude(x, y[, magnitude[, stream]]) -> magnitude\n",
      "        .   @overload\n",
      "        .    computes magnitude of each (x(i), y(i)) vector\n",
      "        .    supports only floating-point source\n",
      "        .   @param x Source matrix containing real components ( CV_32FC1 ).\n",
      "        .   @param y Source matrix containing imaginary components ( CV_32FC1 ).\n",
      "        .   @param magnitude Destination matrix of float magnitudes ( CV_32FC1 ).\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "    \n",
      "    magnitudeSqr(...)\n",
      "        magnitudeSqr(xy[, magnitude[, stream]]) -> magnitude\n",
      "        .   @brief Computes squared magnitudes of complex matrix elements.\n",
      "        .   \n",
      "        .   @param xy Source complex matrix in the interleaved format ( CV_32FC2 ).\n",
      "        .   @param magnitude Destination matrix of float magnitude squares ( CV_32FC1 ).\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        \n",
      "        \n",
      "        \n",
      "        magnitudeSqr(x, y[, magnitude[, stream]]) -> magnitude\n",
      "        .   @overload\n",
      "        .    computes squared magnitude of each (x(i), y(i)) vector\n",
      "        .    supports only floating-point source\n",
      "        .   @param x Source matrix containing real components ( CV_32FC1 ).\n",
      "        .   @param y Source matrix containing imaginary components ( CV_32FC1 ).\n",
      "        .   @param magnitude Destination matrix of float magnitude squares ( CV_32FC1 ).\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "    \n",
      "    max(...)\n",
      "        max(src1, src2[, dst[, stream]]) -> dst\n",
      "        .   @brief Computes the per-element maximum of two matrices (or a matrix and a scalar).\n",
      "        .   \n",
      "        .   @param src1 First source matrix or scalar.\n",
      "        .   @param src2 Second source matrix or scalar.\n",
      "        .   @param dst Destination matrix that has the same size and type as the input array(s).\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa max\n",
      "    \n",
      "    meanShiftFiltering(...)\n",
      "        meanShiftFiltering(src, sp, sr[, dst[, criteria[, stream]]]) -> dst\n",
      "        .   @brief Performs mean-shift filtering for each point of the source image.\n",
      "        .   \n",
      "        .   @param src Source image. Only CV_8UC4 images are supported for now.\n",
      "        .   @param dst Destination image containing the color of mapped points. It has the same size and type\n",
      "        .   as src .\n",
      "        .   @param sp Spatial window radius.\n",
      "        .   @param sr Color window radius.\n",
      "        .   @param criteria Termination criteria. See TermCriteria.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   It maps each point of the source image into another point. As a result, you have a new color and new\n",
      "        .   position of each point.\n",
      "    \n",
      "    meanShiftProc(...)\n",
      "        meanShiftProc(src, sp, sr[, dstr[, dstsp[, criteria[, stream]]]]) -> dstr, dstsp\n",
      "        .   @brief Performs a mean-shift procedure and stores information about processed points (their colors and\n",
      "        .   positions) in two images.\n",
      "        .   \n",
      "        .   @param src Source image. Only CV_8UC4 images are supported for now.\n",
      "        .   @param dstr Destination image containing the color of mapped points. The size and type is the same\n",
      "        .   as src .\n",
      "        .   @param dstsp Destination image containing the position of mapped points. The size is the same as\n",
      "        .   src size. The type is CV_16SC2 .\n",
      "        .   @param sp Spatial window radius.\n",
      "        .   @param sr Color window radius.\n",
      "        .   @param criteria Termination criteria. See TermCriteria.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa cuda::meanShiftFiltering\n",
      "    \n",
      "    meanShiftSegmentation(...)\n",
      "        meanShiftSegmentation(src, sp, sr, minsize[, dst[, criteria[, stream]]]) -> dst\n",
      "        .   @brief Performs a mean-shift segmentation of the source image and eliminates small segments.\n",
      "        .   \n",
      "        .   @param src Source image. Only CV_8UC4 images are supported for now.\n",
      "        .   @param dst Segmented image with the same size and type as src (host or gpu memory).\n",
      "        .   @param sp Spatial window radius.\n",
      "        .   @param sr Color window radius.\n",
      "        .   @param minsize Minimum segment size. Smaller segments are merged.\n",
      "        .   @param criteria Termination criteria. See TermCriteria.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "    \n",
      "    meanStdDev(...)\n",
      "        meanStdDev(mtx, mean, stddev) -> None\n",
      "        .   @brief Computes a mean value and a standard deviation of matrix elements.\n",
      "        .   \n",
      "        .   @param mtx Source matrix. CV_8UC1 matrices are supported for now.\n",
      "        .   @param mean Mean value.\n",
      "        .   @param stddev Standard deviation value.\n",
      "        .   \n",
      "        .   @sa meanStdDev\n",
      "        \n",
      "        \n",
      "        \n",
      "        meanStdDev(mtx[, dst[, stream]]) -> dst\n",
      "        .   @overload\n",
      "    \n",
      "    merge(...)\n",
      "        merge(src, n[, dst[, stream]]) -> dst\n",
      "        .   @brief Makes a multi-channel matrix out of several single-channel matrices.\n",
      "        .   \n",
      "        .   @param src Array/vector of source matrices.\n",
      "        .   @param n Number of source matrices.\n",
      "        .   @param dst Destination matrix.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa merge\n",
      "        \n",
      "        \n",
      "        \n",
      "        merge(src[, dst[, stream]]) -> dst\n",
      "        .   @overload\n",
      "    \n",
      "    min(...)\n",
      "        min(src1, src2[, dst[, stream]]) -> dst\n",
      "        .   @brief Computes the per-element minimum of two matrices (or a matrix and a scalar).\n",
      "        .   \n",
      "        .   @param src1 First source matrix or scalar.\n",
      "        .   @param src2 Second source matrix or scalar.\n",
      "        .   @param dst Destination matrix that has the same size and type as the input array(s).\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa min\n",
      "    \n",
      "    minMax(...)\n",
      "        minMax(src, minVal, maxVal[, mask]) -> None\n",
      "        .   @brief Finds global minimum and maximum matrix elements and returns their values.\n",
      "        .   \n",
      "        .   @param src Single-channel source image.\n",
      "        .   @param minVal Pointer to the returned minimum value. Use NULL if not required.\n",
      "        .   @param maxVal Pointer to the returned maximum value. Use NULL if not required.\n",
      "        .   @param mask Optional mask to select a sub-matrix.\n",
      "        .   \n",
      "        .   The function does not work with CV_64F images on GPUs with the compute capability \\< 1.3.\n",
      "        .   \n",
      "        .   @sa minMaxLoc\n",
      "    \n",
      "    minMaxLoc(...)\n",
      "        minMaxLoc(src, minVal, maxVal, minLoc, maxLoc[, mask]) -> None\n",
      "        .   @brief Finds global minimum and maximum matrix elements and returns their values with locations.\n",
      "        .   \n",
      "        .   @param src Single-channel source image.\n",
      "        .   @param minVal Pointer to the returned minimum value. Use NULL if not required.\n",
      "        .   @param maxVal Pointer to the returned maximum value. Use NULL if not required.\n",
      "        .   @param minLoc Pointer to the returned minimum location. Use NULL if not required.\n",
      "        .   @param maxLoc Pointer to the returned maximum location. Use NULL if not required.\n",
      "        .   @param mask Optional mask to select a sub-matrix.\n",
      "        .   \n",
      "        .   The function does not work with CV_64F images on GPU with the compute capability \\< 1.3.\n",
      "        .   \n",
      "        .   @sa minMaxLoc\n",
      "    \n",
      "    mulAndScaleSpectrums(...)\n",
      "        mulAndScaleSpectrums(src1, src2, flags, scale[, dst[, conjB[, stream]]]) -> dst\n",
      "        .   @brief Performs a per-element multiplication of two Fourier spectrums and scales the result.\n",
      "        .   \n",
      "        .   @param src1 First spectrum.\n",
      "        .   @param src2 Second spectrum with the same size and type as a .\n",
      "        .   @param dst Destination spectrum.\n",
      "        .   @param flags Mock parameter used for CPU/CUDA interfaces similarity, simply add a `0` value.\n",
      "        .   @param scale Scale constant.\n",
      "        .   @param conjB Optional flag to specify if the second spectrum needs to be conjugated before the\n",
      "        .   multiplication.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   Only full (not packed) CV_32FC2 complex spectrums in the interleaved format are supported for now.\n",
      "        .   \n",
      "        .   @sa mulSpectrums\n",
      "    \n",
      "    mulSpectrums(...)\n",
      "        mulSpectrums(src1, src2, flags[, dst[, conjB[, stream]]]) -> dst\n",
      "        .   @brief Performs a per-element multiplication of two Fourier spectrums.\n",
      "        .   \n",
      "        .   @param src1 First spectrum.\n",
      "        .   @param src2 Second spectrum with the same size and type as a .\n",
      "        .   @param dst Destination spectrum.\n",
      "        .   @param flags Mock parameter used for CPU/CUDA interfaces similarity.\n",
      "        .   @param conjB Optional flag to specify if the second spectrum needs to be conjugated before the\n",
      "        .   multiplication.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   Only full (not packed) CV_32FC2 complex spectrums in the interleaved format are supported for now.\n",
      "        .   \n",
      "        .   @sa mulSpectrums\n",
      "    \n",
      "    multiply(...)\n",
      "        multiply(src1, src2[, dst[, scale[, dtype[, stream]]]]) -> dst\n",
      "        .   @brief Computes a matrix-matrix or matrix-scalar per-element product.\n",
      "        .   \n",
      "        .   @param src1 First source matrix or scalar.\n",
      "        .   @param src2 Second source matrix or scalar.\n",
      "        .   @param dst Destination matrix that has the same size and number of channels as the input array(s).\n",
      "        .   The depth is defined by dtype or src1 depth.\n",
      "        .   @param scale Optional scale factor.\n",
      "        .   @param dtype Optional depth of the output array.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa multiply\n",
      "    \n",
      "    norm(...)\n",
      "        norm(src1, normType[, mask]) -> retval\n",
      "        .   @brief Returns the norm of a matrix (or difference of two matrices).\n",
      "        .   \n",
      "        .   @param src1 Source matrix. Any matrices except 64F are supported.\n",
      "        .   @param normType Norm type. NORM_L1 , NORM_L2 , and NORM_INF are supported for now.\n",
      "        .   @param mask optional operation mask; it must have the same size as src1 and CV_8UC1 type.\n",
      "        .   \n",
      "        .   @sa norm\n",
      "        \n",
      "        \n",
      "        \n",
      "        norm(src1, src2[, normType]) -> retval\n",
      "        .   @brief Returns the difference of two matrices.\n",
      "        .   \n",
      "        .   @param src1 Source matrix. Any matrices except 64F are supported.\n",
      "        .   @param src2 Second source matrix (if any) with the same size and type as src1.\n",
      "        .   @param normType Norm type. NORM_L1 , NORM_L2 , and NORM_INF are supported for now.\n",
      "        .   \n",
      "        .   @sa norm\n",
      "    \n",
      "    normalize(...)\n",
      "        normalize(src, alpha, beta, norm_type, dtype[, dst[, mask[, stream]]]) -> dst\n",
      "        .   @brief Normalizes the norm or value range of an array.\n",
      "        .   \n",
      "        .   @param src Input array.\n",
      "        .   @param dst Output array of the same size as src .\n",
      "        .   @param alpha Norm value to normalize to or the lower range boundary in case of the range\n",
      "        .   normalization.\n",
      "        .   @param beta Upper range boundary in case of the range normalization; it is not used for the norm\n",
      "        .   normalization.\n",
      "        .   @param norm_type Normalization type ( NORM_MINMAX , NORM_L2 , NORM_L1 or NORM_INF ).\n",
      "        .   @param dtype When negative, the output array has the same type as src; otherwise, it has the same\n",
      "        .   number of channels as src and the depth =CV_MAT_DEPTH(dtype).\n",
      "        .   @param mask Optional operation mask.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa normalize\n",
      "    \n",
      "    phase(...)\n",
      "        phase(x, y[, angle[, angleInDegrees[, stream]]]) -> angle\n",
      "        .   @brief Computes polar angles of complex matrix elements.\n",
      "        .   \n",
      "        .   @param x Source matrix containing real components ( CV_32FC1 ).\n",
      "        .   @param y Source matrix containing imaginary components ( CV_32FC1 ).\n",
      "        .   @param angle Destination matrix of angles ( CV_32FC1 ).\n",
      "        .   @param angleInDegrees Flag for angles that must be evaluated in degrees.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa phase\n",
      "    \n",
      "    polarToCart(...)\n",
      "        polarToCart(magnitude, angle[, x[, y[, angleInDegrees[, stream]]]]) -> x, y\n",
      "        .   @brief Converts polar coordinates into Cartesian.\n",
      "        .   \n",
      "        .   @param magnitude Source matrix containing magnitudes ( CV_32FC1 or CV_64FC1 ).\n",
      "        .   @param angle Source matrix containing angles ( same type as magnitude ).\n",
      "        .   @param x Destination matrix of real components ( same type as magnitude ).\n",
      "        .   @param y Destination matrix of imaginary components ( same type as magnitude ).\n",
      "        .   @param angleInDegrees Flag that indicates angles in degrees.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "    \n",
      "    pow(...)\n",
      "        pow(src, power[, dst[, stream]]) -> dst\n",
      "        .   @brief Raises every matrix element to a power.\n",
      "        .   \n",
      "        .   @param src Source matrix.\n",
      "        .   @param power Exponent of power.\n",
      "        .   @param dst Destination matrix with the same size and type as src .\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   The function pow raises every element of the input matrix to power :\n",
      "        .   \n",
      "        .   \\f[\\texttt{dst} (I) =  \\fork{\\texttt{src}(I)^power}{if \\texttt{power} is integer}{|\\texttt{src}(I)|^power}{otherwise}\\f]\n",
      "        .   \n",
      "        .   @sa pow\n",
      "    \n",
      "    printCudaDeviceInfo(...)\n",
      "        printCudaDeviceInfo(device) -> None\n",
      "        .\n",
      "    \n",
      "    printShortCudaDeviceInfo(...)\n",
      "        printShortCudaDeviceInfo(device) -> None\n",
      "        .\n",
      "    \n",
      "    pyrDown(...)\n",
      "        pyrDown(src[, dst[, stream]]) -> dst\n",
      "        .   @brief Smoothes an image and downsamples it.\n",
      "        .   \n",
      "        .   @param src Source image.\n",
      "        .   @param dst Destination image. Will have Size((src.cols+1)/2, (src.rows+1)/2) size and the same\n",
      "        .   type as src .\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa pyrDown\n",
      "    \n",
      "    pyrUp(...)\n",
      "        pyrUp(src[, dst[, stream]]) -> dst\n",
      "        .   @brief Upsamples an image and then smoothes it.\n",
      "        .   \n",
      "        .   @param src Source image.\n",
      "        .   @param dst Destination image. Will have Size(src.cols\\*2, src.rows\\*2) size and the same type as\n",
      "        .   src .\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "    \n",
      "    rectStdDev(...)\n",
      "        rectStdDev(src, sqr, rect[, dst[, stream]]) -> dst\n",
      "        .   @brief Computes a standard deviation of integral images.\n",
      "        .   \n",
      "        .   @param src Source image. Only the CV_32SC1 type is supported.\n",
      "        .   @param sqr Squared source image. Only the CV_32FC1 type is supported.\n",
      "        .   @param dst Destination image with the same type and size as src .\n",
      "        .   @param rect Rectangular window.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "    \n",
      "    reduce(...)\n",
      "        reduce(mtx, dim, reduceOp[, vec[, dtype[, stream]]]) -> vec\n",
      "        .   @brief Reduces a matrix to a vector.\n",
      "        .   \n",
      "        .   @param mtx Source 2D matrix.\n",
      "        .   @param vec Destination vector. Its size and type is defined by dim and dtype parameters.\n",
      "        .   @param dim Dimension index along which the matrix is reduced. 0 means that the matrix is reduced\n",
      "        .   to a single row. 1 means that the matrix is reduced to a single column.\n",
      "        .   @param reduceOp Reduction operation that could be one of the following:\n",
      "        .   -   **CV_REDUCE_SUM** The output is the sum of all rows/columns of the matrix.\n",
      "        .   -   **CV_REDUCE_AVG** The output is the mean vector of all rows/columns of the matrix.\n",
      "        .   -   **CV_REDUCE_MAX** The output is the maximum (column/row-wise) of all rows/columns of the\n",
      "        .   matrix.\n",
      "        .   -   **CV_REDUCE_MIN** The output is the minimum (column/row-wise) of all rows/columns of the\n",
      "        .   matrix.\n",
      "        .   @param dtype When it is negative, the destination vector will have the same type as the source\n",
      "        .   matrix. Otherwise, its type will be CV_MAKE_TYPE(CV_MAT_DEPTH(dtype), mtx.channels()) .\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   The function reduce reduces the matrix to a vector by treating the matrix rows/columns as a set of\n",
      "        .   1D vectors and performing the specified operation on the vectors until a single row/column is\n",
      "        .   obtained. For example, the function can be used to compute horizontal and vertical projections of a\n",
      "        .   raster image. In case of CV_REDUCE_SUM and CV_REDUCE_AVG , the output may have a larger element\n",
      "        .   bit-depth to preserve accuracy. And multi-channel arrays are also supported in these two reduction\n",
      "        .   modes.\n",
      "        .   \n",
      "        .   @sa reduce\n",
      "    \n",
      "    registerPageLocked(...)\n",
      "        registerPageLocked(m) -> None\n",
      "        .   @brief Page-locks the memory of matrix and maps it for the device(s).\n",
      "        .   \n",
      "        .   @param m Input matrix.\n",
      "    \n",
      "    remap(...)\n",
      "        remap(src, xmap, ymap, interpolation[, dst[, borderMode[, borderValue[, stream]]]]) -> dst\n",
      "        .   @brief Applies a generic geometrical transformation to an image.\n",
      "        .   \n",
      "        .   @param src Source image.\n",
      "        .   @param dst Destination image with the size the same as xmap and the type the same as src .\n",
      "        .   @param xmap X values. Only CV_32FC1 type is supported.\n",
      "        .   @param ymap Y values. Only CV_32FC1 type is supported.\n",
      "        .   @param interpolation Interpolation method (see resize ). INTER_NEAREST , INTER_LINEAR and\n",
      "        .   INTER_CUBIC are supported for now.\n",
      "        .   @param borderMode Pixel extrapolation method (see borderInterpolate ). BORDER_REFLECT101 ,\n",
      "        .   BORDER_REPLICATE , BORDER_CONSTANT , BORDER_REFLECT and BORDER_WRAP are supported for now.\n",
      "        .   @param borderValue Value used in case of a constant border. By default, it is 0.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   The function transforms the source image using the specified map:\n",
      "        .   \n",
      "        .   \\f[\\texttt{dst} (x,y) =  \\texttt{src} (xmap(x,y), ymap(x,y))\\f]\n",
      "        .   \n",
      "        .   Values of pixels with non-integer coordinates are computed using the bilinear interpolation.\n",
      "        .   \n",
      "        .   @sa remap\n",
      "    \n",
      "    reprojectImageTo3D(...)\n",
      "        reprojectImageTo3D(disp, Q[, xyzw[, dst_cn[, stream]]]) -> xyzw\n",
      "        .   @brief Reprojects a disparity image to 3D space.\n",
      "        .   \n",
      "        .   @param disp Input single-channel 8-bit unsigned, 16-bit signed, 32-bit signed or 32-bit\n",
      "        .   floating-point disparity image. If 16-bit signed format is used, the values are assumed to have no\n",
      "        .   fractional bits.\n",
      "        .   @param xyzw Output 3- or 4-channel floating-point image of the same size as disp . Each element of\n",
      "        .   xyzw(x,y) contains 3D coordinates (x,y,z) or (x,y,z,1) of the point (x,y) , computed from the\n",
      "        .   disparity map.\n",
      "        .   @param Q \\f$4 \\times 4\\f$ perspective transformation matrix that can be obtained via stereoRectify .\n",
      "        .   @param dst_cn The number of channels for output image. Can be 3 or 4.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa reprojectImageTo3D\n",
      "    \n",
      "    resetDevice(...)\n",
      "        resetDevice() -> None\n",
      "        .   @brief Explicitly destroys and cleans up all resources associated with the current device in the current\n",
      "        .   process.\n",
      "        .   \n",
      "        .   Any subsequent API call to this device will reinitialize the device.\n",
      "    \n",
      "    resize(...)\n",
      "        resize(src, dsize[, dst[, fx[, fy[, interpolation[, stream]]]]]) -> dst\n",
      "        .   @brief Resizes an image.\n",
      "        .   \n",
      "        .   @param src Source image.\n",
      "        .   @param dst Destination image with the same type as src . The size is dsize (when it is non-zero)\n",
      "        .   or the size is computed from src.size() , fx , and fy .\n",
      "        .   @param dsize Destination image size. If it is zero, it is computed as:\n",
      "        .   \\f[\\texttt{dsize = Size(round(fx*src.cols), round(fy*src.rows))}\\f]\n",
      "        .   Either dsize or both fx and fy must be non-zero.\n",
      "        .   @param fx Scale factor along the horizontal axis. If it is zero, it is computed as:\n",
      "        .   \\f[\\texttt{(double)dsize.width/src.cols}\\f]\n",
      "        .   @param fy Scale factor along the vertical axis. If it is zero, it is computed as:\n",
      "        .   \\f[\\texttt{(double)dsize.height/src.rows}\\f]\n",
      "        .   @param interpolation Interpolation method. INTER_NEAREST , INTER_LINEAR and INTER_CUBIC are\n",
      "        .   supported for now.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa resize\n",
      "    \n",
      "    rotate(...)\n",
      "        rotate(src, dsize, angle[, dst[, xShift[, yShift[, interpolation[, stream]]]]]) -> dst\n",
      "        .   @brief Rotates an image around the origin (0,0) and then shifts it.\n",
      "        .   \n",
      "        .   @param src Source image. Supports 1, 3 or 4 channels images with CV_8U , CV_16U or CV_32F\n",
      "        .   depth.\n",
      "        .   @param dst Destination image with the same type as src . The size is dsize .\n",
      "        .   @param dsize Size of the destination image.\n",
      "        .   @param angle Angle of rotation in degrees.\n",
      "        .   @param xShift Shift along the horizontal axis.\n",
      "        .   @param yShift Shift along the vertical axis.\n",
      "        .   @param interpolation Interpolation method. Only INTER_NEAREST , INTER_LINEAR , and INTER_CUBIC\n",
      "        .   are supported.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa cuda::warpAffine\n",
      "    \n",
      "    setBufferPoolConfig(...)\n",
      "        setBufferPoolConfig(deviceId, stackSize, stackCount) -> None\n",
      "        .\n",
      "    \n",
      "    setBufferPoolUsage(...)\n",
      "        setBufferPoolUsage(on) -> None\n",
      "        .\n",
      "    \n",
      "    setDevice(...)\n",
      "        setDevice(device) -> None\n",
      "        .   @brief Sets a device and initializes it for the current thread.\n",
      "        .   \n",
      "        .   @param device System index of a CUDA device starting with 0.\n",
      "        .   \n",
      "        .   If the call of this function is omitted, a default device is initialized at the fist CUDA usage.\n",
      "    \n",
      "    split(...)\n",
      "        split(src, dst[, stream]) -> None\n",
      "        .   @brief Copies each plane of a multi-channel matrix into an array.\n",
      "        .   \n",
      "        .   @param src Source matrix.\n",
      "        .   @param dst Destination array/vector of single-channel matrices.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa split\n",
      "    \n",
      "    sqr(...)\n",
      "        sqr(src[, dst[, stream]]) -> dst\n",
      "        .   @brief Computes a square value of each matrix element.\n",
      "        .   \n",
      "        .   @param src Source matrix.\n",
      "        .   @param dst Destination matrix with the same size and type as src .\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "    \n",
      "    sqrIntegral(...)\n",
      "        sqrIntegral(src[, sqsum[, stream]]) -> sqsum\n",
      "        .   @brief Computes a squared integral image.\n",
      "        .   \n",
      "        .   @param src Source image. Only CV_8UC1 images are supported for now.\n",
      "        .   @param sqsum Squared integral image containing 64-bit unsigned integer values packed into\n",
      "        .   CV_64FC1 .\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "    \n",
      "    sqrSum(...)\n",
      "        sqrSum(src[, mask]) -> retval\n",
      "        .   @brief Returns the squared sum of matrix elements.\n",
      "        .   \n",
      "        .   @param src Source image of any depth except for CV_64F .\n",
      "        .   @param mask optional operation mask; it must have the same size as src1 and CV_8UC1 type.\n",
      "    \n",
      "    sqrt(...)\n",
      "        sqrt(src[, dst[, stream]]) -> dst\n",
      "        .   @brief Computes a square root of each matrix element.\n",
      "        .   \n",
      "        .   @param src Source matrix.\n",
      "        .   @param dst Destination matrix with the same size and type as src .\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa sqrt\n",
      "    \n",
      "    subtract(...)\n",
      "        subtract(src1, src2[, dst[, mask[, dtype[, stream]]]]) -> dst\n",
      "        .   @brief Computes a matrix-matrix or matrix-scalar difference.\n",
      "        .   \n",
      "        .   @param src1 First source matrix or scalar.\n",
      "        .   @param src2 Second source matrix or scalar. Matrix should have the same size and type as src1 .\n",
      "        .   @param dst Destination matrix that has the same size and number of channels as the input array(s).\n",
      "        .   The depth is defined by dtype or src1 depth.\n",
      "        .   @param mask Optional operation mask, 8-bit single channel array, that specifies elements of the\n",
      "        .   destination array to be changed. The mask can be used only with single channel images.\n",
      "        .   @param dtype Optional depth of the output array.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa subtract\n",
      "    \n",
      "    sum(...)\n",
      "        sum(src[, mask]) -> retval\n",
      "        .   @brief Returns the sum of matrix elements.\n",
      "        .   \n",
      "        .   @param src Source image of any depth except for CV_64F .\n",
      "        .   @param mask optional operation mask; it must have the same size as src1 and CV_8UC1 type.\n",
      "        .   \n",
      "        .   @sa sum\n",
      "    \n",
      "    threshold(...)\n",
      "        threshold(src, thresh, maxval, type[, dst[, stream]]) -> retval, dst\n",
      "        .   @brief Applies a fixed-level threshold to each array element.\n",
      "        .   \n",
      "        .   @param src Source array (single-channel).\n",
      "        .   @param dst Destination array with the same size and type as src .\n",
      "        .   @param thresh Threshold value.\n",
      "        .   @param maxval Maximum value to use with THRESH_BINARY and THRESH_BINARY_INV threshold types.\n",
      "        .   @param type Threshold type. For details, see threshold . The THRESH_OTSU and THRESH_TRIANGLE\n",
      "        .   threshold types are not supported.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa threshold\n",
      "    \n",
      "    transpose(...)\n",
      "        transpose(src1[, dst[, stream]]) -> dst\n",
      "        .   @brief Transposes a matrix.\n",
      "        .   \n",
      "        .   @param src1 Source matrix. 1-, 4-, 8-byte element sizes are supported for now.\n",
      "        .   @param dst Destination matrix.\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa transpose\n",
      "    \n",
      "    unregisterPageLocked(...)\n",
      "        unregisterPageLocked(m) -> None\n",
      "        .   @brief Unmaps the memory of matrix and makes it pageable again.\n",
      "        .   \n",
      "        .   @param m Input matrix.\n",
      "    \n",
      "    warpAffine(...)\n",
      "        warpAffine(src, M, dsize[, dst[, flags[, borderMode[, borderValue[, stream]]]]]) -> dst\n",
      "        .   @brief Applies an affine transformation to an image.\n",
      "        .   \n",
      "        .   @param src Source image. CV_8U , CV_16U , CV_32S , or CV_32F depth and 1, 3, or 4 channels are\n",
      "        .   supported.\n",
      "        .   @param dst Destination image with the same type as src . The size is dsize .\n",
      "        .   @param M *2x3* transformation matrix.\n",
      "        .   @param dsize Size of the destination image.\n",
      "        .   @param flags Combination of interpolation methods (see resize) and the optional flag\n",
      "        .   WARP_INVERSE_MAP specifying that M is an inverse transformation ( dst=\\>src ). Only\n",
      "        .   INTER_NEAREST , INTER_LINEAR , and INTER_CUBIC interpolation methods are supported.\n",
      "        .   @param borderMode\n",
      "        .   @param borderValue\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa warpAffine\n",
      "    \n",
      "    warpPerspective(...)\n",
      "        warpPerspective(src, M, dsize[, dst[, flags[, borderMode[, borderValue[, stream]]]]]) -> dst\n",
      "        .   @brief Applies a perspective transformation to an image.\n",
      "        .   \n",
      "        .   @param src Source image. CV_8U , CV_16U , CV_32S , or CV_32F depth and 1, 3, or 4 channels are\n",
      "        .   supported.\n",
      "        .   @param dst Destination image with the same type as src . The size is dsize .\n",
      "        .   @param M *3x3* transformation matrix.\n",
      "        .   @param dsize Size of the destination image.\n",
      "        .   @param flags Combination of interpolation methods (see resize ) and the optional flag\n",
      "        .   WARP_INVERSE_MAP specifying that M is the inverse transformation ( dst =\\> src ). Only\n",
      "        .   INTER_NEAREST , INTER_LINEAR , and INTER_CUBIC interpolation methods are supported.\n",
      "        .   @param borderMode\n",
      "        .   @param borderValue\n",
      "        .   @param stream Stream for the asynchronous version.\n",
      "        .   \n",
      "        .   @sa warpPerspective\n",
      "\n",
      "DATA\n",
      "    ALPHA_ATOP = 3\n",
      "    ALPHA_ATOP_PREMUL = 9\n",
      "    ALPHA_IN = 1\n",
      "    ALPHA_IN_PREMUL = 7\n",
      "    ALPHA_OUT = 2\n",
      "    ALPHA_OUT_PREMUL = 8\n",
      "    ALPHA_OVER = 0\n",
      "    ALPHA_OVER_PREMUL = 6\n",
      "    ALPHA_PLUS = 5\n",
      "    ALPHA_PLUS_PREMUL = 11\n",
      "    ALPHA_PREMUL = 12\n",
      "    ALPHA_XOR = 4\n",
      "    ALPHA_XOR_PREMUL = 10\n",
      "    COLOR_BAYER_BG2BGR_MHT = 256\n",
      "    COLOR_BAYER_BG2GRAY_MHT = 260\n",
      "    COLOR_BAYER_BG2RGB_MHT = 258\n",
      "    COLOR_BAYER_GB2BGR_MHT = 257\n",
      "    COLOR_BAYER_GB2GRAY_MHT = 261\n",
      "    COLOR_BAYER_GB2RGB_MHT = 259\n",
      "    COLOR_BAYER_GR2BGR_MHT = 259\n",
      "    COLOR_BAYER_GR2GRAY_MHT = 263\n",
      "    COLOR_BAYER_GR2RGB_MHT = 257\n",
      "    COLOR_BAYER_RG2BGR_MHT = 258\n",
      "    COLOR_BAYER_RG2GRAY_MHT = 262\n",
      "    COLOR_BAYER_RG2RGB_MHT = 256\n",
      "    COLOR_BayerBG2BGR_MHT = 256\n",
      "    COLOR_BayerBG2GRAY_MHT = 260\n",
      "    COLOR_BayerBG2RGB_MHT = 258\n",
      "    COLOR_BayerGB2BGR_MHT = 257\n",
      "    COLOR_BayerGB2GRAY_MHT = 261\n",
      "    COLOR_BayerGB2RGB_MHT = 259\n",
      "    COLOR_BayerGR2BGR_MHT = 259\n",
      "    COLOR_BayerGR2GRAY_MHT = 263\n",
      "    COLOR_BayerGR2RGB_MHT = 257\n",
      "    COLOR_BayerRG2BGR_MHT = 258\n",
      "    COLOR_BayerRG2GRAY_MHT = 262\n",
      "    COLOR_BayerRG2RGB_MHT = 256\n",
      "    DEVICE_INFO_COMPUTE_MODE_DEFAULT = 0\n",
      "    DEVICE_INFO_COMPUTE_MODE_EXCLUSIVE = 1\n",
      "    DEVICE_INFO_COMPUTE_MODE_EXCLUSIVE_PROCESS = 3\n",
      "    DEVICE_INFO_COMPUTE_MODE_PROHIBITED = 2\n",
      "    DYNAMIC_PARALLELISM = 35\n",
      "    DeviceInfo_ComputeModeDefault = 0\n",
      "    DeviceInfo_ComputeModeExclusive = 1\n",
      "    DeviceInfo_ComputeModeExclusiveProcess = 3\n",
      "    DeviceInfo_ComputeModeProhibited = 2\n",
      "    EVENT_BLOCKING_SYNC = 1\n",
      "    EVENT_DEFAULT = 0\n",
      "    EVENT_DISABLE_TIMING = 2\n",
      "    EVENT_INTERPROCESS = 4\n",
      "    Event_BLOCKING_SYNC = 1\n",
      "    Event_DEFAULT = 0\n",
      "    Event_DISABLE_TIMING = 2\n",
      "    Event_INTERPROCESS = 4\n",
      "    FEATURE_SET_COMPUTE_10 = 10\n",
      "    FEATURE_SET_COMPUTE_11 = 11\n",
      "    FEATURE_SET_COMPUTE_12 = 12\n",
      "    FEATURE_SET_COMPUTE_13 = 13\n",
      "    FEATURE_SET_COMPUTE_20 = 20\n",
      "    FEATURE_SET_COMPUTE_21 = 21\n",
      "    FEATURE_SET_COMPUTE_30 = 30\n",
      "    FEATURE_SET_COMPUTE_32 = 32\n",
      "    FEATURE_SET_COMPUTE_35 = 35\n",
      "    FEATURE_SET_COMPUTE_50 = 50\n",
      "    GLOBAL_ATOMICS = 11\n",
      "    HOST_MEM_PAGE_LOCKED = 1\n",
      "    HOST_MEM_SHARED = 2\n",
      "    HOST_MEM_WRITE_COMBINED = 4\n",
      "    HostMem_PAGE_LOCKED = 1\n",
      "    HostMem_SHARED = 2\n",
      "    HostMem_WRITE_COMBINED = 4\n",
      "    NATIVE_DOUBLE = 13\n",
      "    NVIDIA_OPTICAL_FLOW_1_0_NV_OF_PERF_LEVEL_FAST = 20\n",
      "    NVIDIA_OPTICAL_FLOW_1_0_NV_OF_PERF_LEVEL_MAX = 21\n",
      "    NVIDIA_OPTICAL_FLOW_1_0_NV_OF_PERF_LEVEL_MEDIUM = 10\n",
      "    NVIDIA_OPTICAL_FLOW_1_0_NV_OF_PERF_LEVEL_SLOW = 5\n",
      "    NVIDIA_OPTICAL_FLOW_1_0_NV_OF_PERF_LEVEL_UNDEFINED = 0\n",
      "    NvidiaOpticalFlow_1_0_NV_OF_PERF_LEVEL_FAST = 20\n",
      "    NvidiaOpticalFlow_1_0_NV_OF_PERF_LEVEL_MAX = 21\n",
      "    NvidiaOpticalFlow_1_0_NV_OF_PERF_LEVEL_MEDIUM = 10\n",
      "    NvidiaOpticalFlow_1_0_NV_OF_PERF_LEVEL_SLOW = 5\n",
      "    NvidiaOpticalFlow_1_0_NV_OF_PERF_LEVEL_UNDEFINED = 0\n",
      "    SHARED_ATOMICS = 12\n",
      "    SURF_CUDA_ANGLE_ROW = 5\n",
      "    SURF_CUDA_HESSIAN_ROW = 6\n",
      "    SURF_CUDA_LAPLACIAN_ROW = 2\n",
      "    SURF_CUDA_OCTAVE_ROW = 3\n",
      "    SURF_CUDA_ROWS_COUNT = 7\n",
      "    SURF_CUDA_SIZE_ROW = 4\n",
      "    SURF_CUDA_X_ROW = 0\n",
      "    SURF_CUDA_Y_ROW = 1\n",
      "    WARP_SHUFFLE_FUNCTIONS = 30\n",
      "\n",
      "FILE\n",
      "    (built-in)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cv2.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function Stream_Null:\n",
      "\n",
      "Stream_Null(...)\n",
      "    Stream_Null() -> retval\n",
      "    .   @brief Adds a callback to be called on the host after all currently enqueued items in the stream have\n",
      "    .       completed.\n",
      "    .   \n",
      "    .       @note Callbacks must not make any CUDA API calls. Callbacks must not perform any synchronization\n",
      "    .       that may depend on outstanding device work or other callbacks that are not mandated to run earlier.\n",
      "    .       Callbacks without a mandated order (in independent streams) execute in undefined order and may be\n",
      "    .       serialized.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cv2.cuda.Stream_Null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
